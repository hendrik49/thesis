<!DOCTYPE html>
<!-- saved from url=(0027)http://sci2s.ugr.es/BigData -->
<html class="js"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">

<meta name="viewport" content="width=device-width">
<link rel="shortcut icon" href="http://sci2s.ugr.es/sites/default/files/favIcon_0_0.png" type="image/png">
<link rel="shortlink" href="http://sci2s.ugr.es/node/284">
<link rel="canonical" href="http://sci2s.ugr.es/BigData">
<meta name="Generator" content="Drupal 7 (http://drupal.org)">
<script async="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/analytics.js.download"></script><script type="text/x-mathjax-config;executed=true">
MathJax.Hub.Config({
  extensions: ['tex2jax.js'],
  jax: ['input/TeX','output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$','$'], ['\\(','\\)'] ],
    processEscapes: true,
    processClass: 'tex2jax',
    ignoreClass: 'html'
  },
  showProcessingMessages: false,
  messageStyle: 'none'
});
</script><title>Big Data: Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes | Soft Computing and Intelligent Information Systems</title>
<style type="text/css" media="all">
@import url("http://sci2s.ugr.es/modules/system/system.base.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/system/system.menus.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/system/system.messages.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/system/system.theme.css?o42y4r");
</style>
<style type="text/css" media="all">
@import url("http://sci2s.ugr.es/sites/all/modules/date/date_api/date.css?o42y4r");
@import url("http://sci2s.ugr.es/sites/all/modules/date/date_popup/themes/datepicker.1.7.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/field/theme/field.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/node/node.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/search/search.css?o42y4r");
@import url("http://sci2s.ugr.es/modules/user/user.css?o42y4r");
@import url("http://sci2s.ugr.es/sites/all/modules/views/css/views.css?o42y4r");
@import url("http://sci2s.ugr.es/sites/all/modules/ckeditor/css/ckeditor.css?o42y4r");
</style>
<style type="text/css" media="all">
@import url("http://sci2s.ugr.es/sites/all/modules/ctools/css/ctools.css?o42y4r");
</style>
<style type="text/css" media="all">
@import url("http://sci2s.ugr.es/sites/all/themes/professional_theme/style.css?o42y4r");
@import url("http://sci2s.ugr.es/sites/all/themes/professional_theme/sci2s.css?o42y4r");
</style>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/jquery.js.download"></script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/jquery.once.js.download"></script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/drupal.js.download"></script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mathjax.js.download"></script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mathjax.js(1).download"></script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/googleanalytics.js.download"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,"script","//www.google-analytics.com/analytics.js","ga");ga("create", "UA-2737819-1", {"cookieDomain":"auto"});ga("set", "anonymizeIp", true);ga("send", "pageview");
//--><!]]>
</script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/custom.js.download"></script>
<script type="text/javascript" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/botonArriba.js.download"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
jQuery.extend(Drupal.settings, {"basePath":"\/","pathPrefix":"","ajaxPageState":{"theme":"professional_theme","theme_token":"qc97EThdvhmsmwcY4cdYdATwYCADoo95dlwzoLWe56s","js":{"misc\/jquery.js":1,"misc\/jquery.once.js":1,"misc\/drupal.js":1,"sites\/all\/modules\/mathjax\/mathjax.js":1,"https:\/\/cdn.mathjax.org\/mathjax\/latest\/MathJax.js?config=TeX-AMS-MML_HTMLorMML":1,"sites\/all\/modules\/google_analytics\/googleanalytics.js":1,"0":1,"sites\/all\/themes\/professional_theme\/js\/custom.js":1,"sites\/all\/themes\/professional_theme\/js\/botonArriba.js":1},"css":{"modules\/system\/system.base.css":1,"modules\/system\/system.menus.css":1,"modules\/system\/system.messages.css":1,"modules\/system\/system.theme.css":1,"sites\/all\/modules\/date\/date_api\/date.css":1,"sites\/all\/modules\/date\/date_popup\/themes\/datepicker.1.7.css":1,"modules\/field\/theme\/field.css":1,"modules\/node\/node.css":1,"modules\/search\/search.css":1,"modules\/user\/user.css":1,"sites\/all\/modules\/views\/css\/views.css":1,"sites\/all\/modules\/ckeditor\/css\/ckeditor.css":1,"sites\/all\/modules\/ctools\/css\/ctools.css":1,"sites\/all\/themes\/professional_theme\/style.css":1,"sites\/all\/themes\/professional_theme\/sci2s.css":1}},"googleanalytics":{"trackOutbound":1,"trackMailto":1,"trackDownload":1,"trackDownloadExtensions":"7z|aac|arc|arj|asf|asx|avi|bin|csv|doc(x|m)?|dot(x|m)?|exe|flv|gif|gz|gzip|hqx|jar|jpe?g|js|mp(2|3|4|e?g)|mov(ie)?|msi|msp|pdf|phps|png|ppt(x|m)?|pot(x|m)?|pps(x|m)?|ppam|sld(x|m)?|thmx|qtm?|ra(m|r)?|sea|sit|tar|tgz|torrent|txt|wav|wma|wmv|wpd|xls(x|m|b)?|xlt(x|m)|xlam|xml|z|zip"},"urlIsAjaxTrusted":{"\/BigData":true,"\/BigData?destination=node\/284":true}});
//--><!]]>
</script>
<!--[if lt IE 9]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.0') format('woff'), url('https://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.0') format('opentype')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body class="html not-front not-logged-in one-sidebar sidebar-first page-node page-node- page-node-284 node-type-page"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
    
<div id="wrapper">
  <header id="header" role="banner">
    <div id="logo"><a href="http://sci2s.ugr.es/" title="Home"><img src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logoSCI2S_6.png"></a></div>    <h1 id="site-title"><a href="http://sci2s.ugr.es/" title="Home">Soft Computing and Intelligent Information Systems</a></h1>
    <div id="site-description">A <a href="http://www.ugr.es/">University of Granada</a> research group</div>
    <div class="clear"></div>
    <nav id="main-menu" role="navigation">
      <a class="nav-toggle" href="http://sci2s.ugr.es/BigData#">Navigation</a>
      <div class="menu-navigation-container">
        <ul class="menu"><li class="first expanded"><a href="http://sci2s.ugr.es/about" title="About the SCI2S research group">About</a><ul class="menu"><li class="first leaf"><a href="http://sci2s.ugr.es/members">Members</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/colaborations">International Collaborations</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/links">Links of Interest</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/contact">Contact</a></li>
</ul></li>
<li class="expanded"><a href="http://sci2s.ugr.es/labs" title="The research group is organized in seven different laboratories">Laboratories</a><ul class="menu"><li class="first leaf"><a href="http://sci2s.ugr.es/efdamis" title="Evolutionary and Fuzzy Data Mining &amp; Intelligent Systems Lab">EFDAMIS Lab</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/m4m" title="Bioinformatics Minning, Modeling, Annotating, Predicting Lab">M4M Lab</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/decmak" title="Decision Making Lab">DECMAK Lab</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/soccer" title="Image Registration Applying Metaheuristics Lab">SOCCER Lab</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/gabic" title="Genetic Algorithms &amp; Biologically Inspired Computation Lab">GABIC Lab</a></li>
<li class="leaf"><a href="http://secaba.ugr.es/" title="Quality Evaluation and Information Retrieval">SECABA Lab</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/dicits" title="Distributed Computational Intelligence and Time Series">DiCITS Lab</a></li>
</ul></li>
<li class="expanded"><a href="http://sci2s.ugr.es/research" title="Research Activities of the Group">Research</a><ul class="menu"><li class="first leaf"><a href="http://sci2s.ugr.es/publications?pubType=PhD" title="Ph.D. Advised by the Research Group">Advised Ph.D.</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/specialIssues" title="Guest editors of journal special issues">Edited Special Issues</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/editedBooks" title="Books edited by the research group">Edited Books</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/editorialBoards" title="Journal Editorial Boards">Editorial Boards</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/scientificImpact" title="Scientific Impact: Bibliometrics and Highly Cited Papers">Scientific Impact</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/conferenceActivities" title="Conference Organization, Edited Proceedings and Invited Special Sessions">Conference Activities</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/researchProjects">Research Projects</a></li>
<li class="last leaf"><a href="http://rankinguniversidades.es/" title="Rankings I-UGR de Universidades Españolas según Campos y Disciplinas Científicas">Rankings I-UGR</a></li>
</ul></li>
<li class="expanded"><a href="http://sci2s.ugr.es/publications" title="Publications of the Research Group">Publications</a><ul class="menu"><li class="first leaf"><a href="http://sci2s.ugr.es/books">Books</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/publications?pubType=journal" title="Papers published in Journals">Journal Papers</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/publications?pubType=bookChapter" title="Contributions to Book Chapters">Book Chapters</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/publications?pubType=confContrib" title="Conference Contributions">Conference Contributions</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/qualityReports" title="Reports on the Quality of Libraries">Quality Reports (Libraries)</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/publications?comp=comp" title="Papers with Associated Complementary Material Pages">Complementary Material</a></li>
</ul></li>
<li class="expanded"><a href="http://sci2s.ugr.es/teaching" title="Teaching activities of the group">Teaching</a><ul class="menu"><li class="first leaf"><a href="http://sci2s.ugr.es/graduateCourses" title="Graduate courses at the Escuela Técnica Superior de Ingenierías Informática y de Telecomunicación of the University of Granada">Graduate Courses: ETSIIT</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/postGraduateCourses">Post Graduate Courses</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/otherCourses">Other Courses</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/TutorialsTalks">Tutorials and Plenary Talks</a></li>
</ul></li>
<li class="expanded active-trail"><a href="http://sci2s.ugr.es/thematicWebSites" title="Thematic Web Sites" class="active-trail">Thematic Sites</a><ul class="menu"><li class="first leaf active-trail"><a href="http://sci2s.ugr.es/BigData" title="Big Data: Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes" class="active-trail active">Big Data</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/imbalanced">Classification with Imbalanced Datasets</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/CWDM">Computing with Words in Decision Making</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/books/data-preprocessing">Data Preprocesing in Data Mining</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/EAMHCO" title="Evolutionary Algorithms and other Metaheuristics for Continuous Optimization Problems">E. A. and Metaheur. for Continuous Optim.</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/fss" title="Fuzzy Systems Software: Taxonomy, Current Research Trends and Prospects">Fuzzy Systems Software</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/gfs">Genetic Fuzzy Systems</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/hindex">h-index and Variants</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/fuzzyInterpretability" title="Interpretability of Linguistic Fuzzy Rule-Based Systems: An Overview of Interpretability Measures">Interpretability of FRBSs</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/MVDM">Missing Values in Data Mining</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/noisydata">Noisy Data in Data Mining</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/pr" title="Prototype Reduction in Nearest Neighbor Classification: Prototype Selection and Prototype Generation">Prototype Reduction in N. Neighbor Class.</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/ssl" title="Semi-supervised Classification: An Insight into Self-Labeling Approaches">Semi-supervised Class.: Self-Labeling</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/sicidm" title="Statistical Inference in Computational Intelligence and Data Mining">Statistical Inf. in Comp. Intel. &amp; Data Mining</a></li>
</ul></li>
<li class="expanded"><a href="http://sci2s.ugr.es/node/26" title="Software developed by the group">Software</a><ul class="menu"><li class="first leaf"><a href="http://www.keel.es/" title="Knowledge Extraction based on Evolutionary Learning">KEEL</a></li>
<li class="leaf"><a href="http://www.keel.es/" title="">KEEL-Dataset Repository</a></li>
<li class="leaf"><a href="http://secaba.ugr.es/secaba2" title="">SECABA2</a></li>
<li class="leaf"><a href="http://cran.r-project.org/web/packages/RSNNS/" title="R wrapping for the Stuttgart Neural Network Simulator">RSNNS</a></li>
<li class="leaf"><a href="http://cran.r-project.org/web/packages/frbs" title="Fuzzy Rule-Based Systems for Classification and Regression Tasks">FRBS</a></li>
<li class="leaf"><a href="http://cran.r-project.org/web/packages/RoughSets" title="Data Analysis Using Rough Set and Fuzzy Rough Set Theories">RoughSets</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/scimat" title="Science Mapping Analysis software Tool">SciMAT</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/WoSQP" title="A tool to obtain an exact result count for big queries in the Web of Science web page">WoS Query Partitioner</a></li>
</ul></li>
<li class="leaf"><a href="http://sci2s.ugr.es/prizes" title="Awards and recognitions won by the research group and its members">Awards</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/press" title="News and articles about the group and its members in the press and television">In the Press</a></li>
</ul>      </div>
      <div class="clear"></div>
    </nav><!-- end main-menu -->
  </header>

  
  <div id="container">

		  
  
   
    <div class="content-sidebar-wrap">

    <div id="content">
      <div id="breadcrumbs"><h2 class="element-invisible">You are here</h2><nav class="breadcrumb"><a href="http://sci2s.ugr.es/">Home</a> » <a href="http://sci2s.ugr.es/thematicWebSites" title="Thematic Web Sites">Thematic Sites</a> » Big Data: Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes</nav></div>      <section id="post-content" role="main">
                                <h1 class="page-title">Big Data: Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes</h1>                                        <div class="region region-content">
  <div id="block-system-main" class="block block-system">

      
  <div class="content">
                          <span property="dc:title" content="Big Data: Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes" class="rdf-meta element-hidden"></span>  
      
    
  <div class="content node-page">
    <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even" property="content:encoded"><div class="tex2jax"><p class="rtejustify"><img alt="BigData logo" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/BigData_04.png" style="width: 300px; height: 214px; float: right;"></p>
<p class="rtejustify">The web is organized according to the following summary:</p>
<ol><li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Introduction to Big Data">Introduction to Big Data</a></span></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Big Data Technologies">Big Data Technologies: Hadoop ecosystem and Spark</a></span></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Preprocessing">Big Data preprocessing </a></span></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Imbalanced Big Data">Imbalanced Big Data classification</a></span></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Big-Data-Fuzzy">Big Data classification with fuzzy models</a></span></li>
<li class="rtejustify"><a href="http://sci2s.ugr.es/BigData#kNN"><span style="font-size:16px;">Classification Algorithms: k-NN</span></a></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Applications">Big Data Applications</a></span></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Datasets">Dataset Repository</a></span></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Reviews">Literature review: </a><a href="http://sci2s.ugr.es/BigData#Reviews">surveys and overviews</a></span></li>
<li class="rtejustify"><a href="http://sci2s.ugr.es/BigData#slides"><span style="font-size:16px;">Keynote slides</span></a></li>
<li class="rtejustify"><span style="font-size:16px;"><a href="http://sci2s.ugr.es/BigData#Links">Links of interest</a></span></li>
</ol><p class="rtejustify">This <strong>Website</strong> contains SCI<sup>2</sup>S research material on algorithms for data preprocessing, computational intelligence and classification with imbalanced datasets in the scenario of Big Data. All information shown here is related to the following SCI<sup>2</sup>S journal papers and algorithms developed:</p>
<ul><li class="rtejustify"><strong>J. Maillo, <a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong>&nbsp;<em>kNN-IS: An Iterative Spark-based design of the k-Nearest Neighbors classifier for big data.</em>&nbsp;Knowledge-Based Systems, in press <a href="http://dx.doi.org/10.1016/j.knosys.2016.06.012">doi: 10.1016/j.knosys.2016.06.012 </a><a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/kNN_IS.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li class="rtejustify"><strong>A. Fernandez,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>.&nbsp;<em>Fuzzy Rule Based Classification Systems for Big Data with MapReduce: Granularity Analysis</em>.&nbsp;Advances in Data Analysis and Classification,&nbsp;in press.&nbsp;doi: <a href="http://dx.doi.org/10.1007/s11634-016-0260-z">10.1007/s11634-016-0260-z</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/2086_2016-ADAC-FuzzyGranularityBigData.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li class="rtejustify"><strong>A. Fernandez, C.J. Carmona, M.J. del Jesus,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>.&nbsp;<em>A View on Fuzzy Systems for Big Data: Progress and Opportunities</em>.&nbsp;International Journal of Computational Intelligence Systems, 9:1 (2016), 69-80 doi:&nbsp;<a href="http://dx.doi.org/10.1080/18756891.2016.1180820">10.1080/18756891.2016.1180820</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/2082_ijcis3726.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li class="rtejustify"><strong><a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, H. Mouriño Talín, D. Martínez-Rego, V. Bolón-Canedo, A. Alonso-Betanzos, J. M. Benítez, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. </strong>Data discretization: taxonomy and big data challenge. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 6:1 (2016) 5-21. doi: <a href="http://dx.doi.org/10.1002/widm.1173">10.1002/widm.1173</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1996_2015-sramirez-taxonomy.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li class="rtejustify"><strong>D. Galpert, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, E. Ancede-Gallardo, A. Antunes, G. Agüero-Chapin.</strong> <em>An Effective Big Data Supervised Imbalanced Classification Approach for Ortholog Detection in Related Yeast Species</em>. BioMed Research International, vol. 2015, Article ID 748681, 12 pages, 2015. doi: <a href="http://www.hindawi.com/journals/bmri/2015/748681/">10.1155/2015/748681&nbsp;</a><a href="http://downloads.hindawi.com/journals/bmri/aip/748681.pdf"> </a> <a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-hindawi-dgalpert.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
<li class="rtejustify"><strong><a href="http://sci2s.ugr.es/members#DPeralta">D. Peralta</a>,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>,&nbsp;<a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong>&nbsp;<em>Evolutionary Feature Selection for Big Data Classification: A&nbsp;MapReduce Approach</em>. Mathematical Problems in Engineering, vol. 2015, Article ID 246139, 11 pages, 2015, doi: <a href="http://www.hindawi.com/journals/mpe/2015/246139/">10.1155/2015/246139</a> <a href="http://sci2s.ugr.es/sites/default/files/2015-hindawi-peralta.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li class="rtejustify"><strong>I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, J. Bacardit,&nbsp;<a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.&nbsp;</strong><em>ROSEFW-RF: The winner algorithm for the ECBDL'14 Big Data Competition: An extremely imbalanced big data bioinformatics problem.</em>&nbsp;Knowledge-Based Systems 87 (2015) 69-79.&nbsp;doi: <a href="http://www.sciencedirect.com/science/article/pii/S0950705115002130">10.1016/j.knosys.2015.05.027</a>&nbsp; <a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-Knosys-triguero_rosefw-RF.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li class="rtejustify"><strong><a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. </strong><em>A MapReduce Approach to Address Big Data Classification Problems Based on the Fusion of Linguistic Fuzzy Rules. </em>International Journal of Computational Intelligence Systems 8:3 (2015) 422-437. doi: <a href="http://dx.doi.org/10.1080/18756891.2015.1017377">10.1080/18756891.2015.1017377</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1860_delRio-lopez-benitez-herrera-Chi-FRBCS-MapReduce.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
<li class="rtejustify"><strong>I. Triguero, <a href="http://sci2s.ugr.es/members#DPeralta">D. Peralta</a>, J. Bacardit, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. </strong><em>MRPR: A MapReduce Solution for Prototype Reduction in Big Data Classification. </em>Neurocomputing 150 (2015), 331-345. doi: <a href="http://dx.doi.org/10.1016/j.neucom.2014.04.078">10.1016/j.neucom.2014.04.078</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1769_2015-Neurocomputing-MRPR-A%20MapReduce%20solution%20for%20prototype%20reduction%20in%20big%20data%20classification.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
<li class="rtejustify"><strong>V. López, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong> <em>Cost-Sensitive Linguistic Fuzzy Rule Based Classification Systems under the MapReduce Framework for Imbalanced Big Data. </em>Fuzzy Sets and Systems 258 (2015) 5-38. doi: <a href="http://dx.doi.org/10.1016/j.fss.2014.01.015">10.1016/j.fss.2014.01.015</a>&nbsp; <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1734_2015-lopez-FSS.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
<li class="rtejustify"><strong><a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. <em>On the use of MapReduce for Imbalanced Big Data using Random Forest. </em>Information Sciences 285 (2014) 112-137. doi: <a href="http://dx.doi.org/10.1016/j.ins.2014.03.043">10.1016/j.ins.2014.03.043</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1742_2014-delRio-INS.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
<li class="rtejustify"><strong>A. Fernandez, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, A. Bawakid, M.J. del Jesus, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. <em>Big Data with Cloud Computing: An Insight on the Computing Environment, MapReduce and Programming Frameworks</em>. WIREs Data Mining and Knowledge Discovery 4:5 (2014) 380-409. doi: <a href="http://dx.doi.org/10.1002/widm.1134">10.1002/widm.1134</a>&nbsp; <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1810_2014-WIRES-Fernandez_etAl-Big_Data_w_Cloud_Computing.pdf"><img alt="PDF Icon" class="iconPdfPub" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
</ul><p class="rtejustify">Throughout this Website, we have also included the&nbsp;<strong>source code for&nbsp;the algorithms</strong> associated with the former papers, as well as <strong>new approaches that are under development. </strong>Readers may find the implementations&nbsp;in the corresponding <em>Github&nbsp;and Spark Packages links </em>placed in those sections devoted to describe each framework. Both are marked with the corresponding logo:</p>
<p class="rtejustify"><a href="https://github.com/"><img alt="Gitthub" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a><a href="http://spark-packages.org/"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/spark-logo.png" style="width: 94px; height: 50px;"></a></p>
<p class="rtejustify">&nbsp;</p>
<h2 class="rtejustify"><a id="Introduction to Big Data" name="Introduction to Big Data"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/BigData_04.png" style="width: 175px; height: 125px; float: left;">Introduction to Big Data</a></h2>
<p>Recently, the term of Big Data has been coined referring to those challenges and advantages derived from collecting and&nbsp;processing vast amounts of data (<em>V.&nbsp;Marx.&nbsp;The big challenges of big data.&nbsp;Nature, 498(7453):255-260, 2013</em>). This topic has appeared since organizations must deal with petabyte-scale&nbsp;collections of data. In fact, in the last two years we have produced 90% of the total data generated in history (<em>X. Wu, X. Zhu, G.-Q. Wu, and W. Ding.&nbsp;Data mining with big data.&nbsp;IEEE&nbsp;Trans. Knowl. Data Eng., 26(1):97-107, 2014</em>). The&nbsp;sources of such huge quantity of information are those applications which gather data from click streams, transaction histories,&nbsp;sensors, and elsewhere. However, the first problem for the correct definition of "Big Data" is the name itself (<em>T.&nbsp;Kraska.&nbsp;Finding the needle in the big data systems haystack.&nbsp;IEEE Internet Comput., 17(1):84-86, 2013</em>),&nbsp;as we might think that it is just related to the data <strong>Volume</strong>.</p>
<p>The heterogeneous structure, diverse dimensionality, and <strong>Variety</strong>&nbsp;of the data representation, has also significance on&nbsp;this issue. Just think about the former applications which carry out the data recording: different software implementations will&nbsp;lead to different schemes and protocols (<em>T. Schlieski and B.D.&nbsp;Johnson.&nbsp;Entertainment in the age of big data.&nbsp;Proceedings of the IEEE, 100(Centennial-Issue):1404-1408,&nbsp;2012</em>).</p>
<p>Of course it also depends on the computational time, i.e. the efficiency and <strong>Velocity</strong>&nbsp;in both receiving and processing the data.&nbsp;Current users demand a "tolerable elapsed time"&nbsp;for receiving an answer. We must put this term in relationship with the available&nbsp;computational resources, as we cannot compare the power of a personal computer with respect to a computational server of a big&nbsp;corporation (<em>S. Madden.&nbsp;From databases to big data.&nbsp;IEEE&nbsp;Internet Comput., 16(3):4-6, 2012</em>).</p>
<p>All these facts are known as the 3V's of Big Data (Figure 1), which lead to the definition given by <a href="http://stevetodd.typepad.com/my_weblog/big-data/">Steve Todd</a> at Berkeley&nbsp;University:</p>
<blockquote><p>Big data is when the normal&nbsp;application of current technology does not enable users to obtain timely, cost-effective, and quality answers to data-driven&nbsp;questions.</p>
</blockquote>
<p>&nbsp;</p>
<p class="rtecenter"><img alt="3 Vs Big Data" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/v3.png" style="width: 300px; height: 244px;"></p>
<p class="rtecenter">Figure 1. The 3 Vs of Big Data</p>
<p>We must point out that additional definitions including up to 9V's can be also found, adding terms like Veracity, Value, Viability, and Visualization, among others (<em>P.C. Zikopoulos, C. Eaton, D. deRoos, T. Deutsch, and G. Lapis.&nbsp;Understanding Big Data - Analytics for Enterprise Class Hadoop and&nbsp;Streaming Data.&nbsp;McGraw-Hill Osborne Media, 1st edition, 2011</em>).</p>
<p>The main challenge when addressing Big Data is associated with two main features (<em>A. Labrinidis and H.V. Jagadish.&nbsp;Challenges and opportunities with big data.&nbsp;PVLDB, 5(12):2032-2033, 2012</em>):</p>
<ul><li>The storage and management of large volumes of information. This issue is related to DBMS, and the traditional entity-relation model. Commercial systems report to scale well, being able to handle multi-petabyte databases, but in addition to their "cost"&nbsp;in terms of price and hardware resources, they have the constraint of importing data into a native representation. On the other hand, widely adopted open source systems, such as MySQL, are much more limited in terms of scalability than their commercial analytics counterparts.</li>
<li>The process for carrying out the exploration of these large volumes of data, which intends to discover useful information and knowledge for future actions (<em>X. Wu, X. Zhu, G.-Q. Wu, and W. Ding.&nbsp;Data mining with big data.&nbsp;IEEE&nbsp;Trans. Knowl. Data Eng., 26(1):97-107, 2014</em>). The standard analytical processing is guided by an entity-relation scheme, from which queries were formulated using the SQL language. The first hitch of these type of systems is the necessity of preloading the data, as stated previously. Additionally, there is not much support for in-database statistics and modeling, and many DM programmers may not be comfortable with the SQL declarative style. Even in the case that engines provide these functionalities, since iterative algorithms are not easily expressible as parallel operations in SQL, they do not work well for massive quantities of data.</li>
</ul><p>In summary, there are several conditions that must be taken into account in order to consider a problem within the Big Data framework. First of all, and referring to the 3Vs' properties, a threshold for the quantity of information that is being processed, and the time constraints for giving an answer, must be established. These two concepts are also closely related. For example, if we address the fingerprint recognition application, there is a limit for the number of fingerprints we can manage in the database for providing an accurate answer within a short period of time, i.e. tenths of a second or few seconds.</p>
<p>But, how do we set this <em>limit</em>? The answer is unclear as what was "big" years ago, can now be considered as "small". Therefore, for a clear definition of Big Data we must also include which technology is necessary to solve the problem. Suppose a <em>major </em>sales enterprise, which aims to adjust the unit pricing for a collection of items based on demand and inventory. Clearly, this firm will need a computational technology beyond a standard cluster of machines with a relational database and a common business analytics product. Now, if we consider a project of similar ambitions within the domain of a retailer company, the application could easily be completed using existing databases and ETL tools. The latter cannot be categorized as Big Data project, according to our definition.</p>
<p>Finally, Big Data is about the insight that we want to extract from information. There are many well-known applications that are based on Cloud Computing such as email servers (Gmail), social media (Twitter), or storage sharing and backup (Dropbox). All this software manage high volumes of data, where fast responses are essential, and with information coming at a high rate in a semistructured or unstructured way. They must also face the veracity in the information; however, they are not intrinsically considered Big Data.</p>
<p>The key here is the analysis that is made for knowledge and business purposes, what is known as Data Science (<em>F. Provost and T. Fawcett.&nbsp;Data Science for Business. What you need to know about data&nbsp;&nbsp;mining and data-analytic thinking.&nbsp;O'Reilly Media, 1st edition, 2013</em>). This speciality include several fields such as statistics, machine learning, DM, artificial intelligence, and visualisation, among others. Hence, Big Data and Data Science are two terms with a high synergy between them (<em>MA&nbsp;Waller, SE&nbsp;Fawcett . Data science, predictive analytics,&nbsp;and big data: a revolution that will transform&nbsp;supply chain design and management. J Bus Logistics&nbsp;2013, 34:77-84</em>). Some well-known examples include e-Sciences and other related scientific disciplines (particle physics, bioinformatics, medicine or genomics) Social Computing (social network analysis, online communities or recommender systems), and large-scale e-commerce, all of which are particularly data-intensive.</p>
<p>Regarding the former, many Big Data challenges proliferate nowadays for encouraging researchers to put their efforts in solving these kind of tasks. As examples, we may refer to the "<a href="http://cruncher.ncl.ac.uk/bdcomp/index.pl">Data Mining Competition 2014</a>", which belongs to the <em>Evolutionary Computation for Big Data and Big Learning Workshop</em> (a part of the well-known GECCO conference), and the three "<a href="http://www.synapse.org/dream">DREAM9</a>" challenges opened by Sage Bionetworks and DREAM, linked to the <em>International Biomedical Commons Congress</em> and the <em>RECOMB/ISCB Systems and Regulatory Genomics/DREAM Conference</em>.</p>
<p>&nbsp;</p>
<h2><a id="Big Data Technologies" name="Big Data Technologies"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/BigData_04.png" style="width: 175px; height: 125px; float: left;">Big Data Technologies: Hadoop ecosystem and Spark</a></h2>
<p class="rteindent4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. <a href="http://sci2s.ugr.es/BigData#intro_mr">Introduction</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. <a href="http://sci2s.ugr.es/BigData#hadoop">Hadoop&nbsp;ecosystem</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. <a href="http://sci2s.ugr.es/BigData#spark">Apache SPARK framework</a></p>
<p>&nbsp;</p>
<h3><a id="intro_mr" name="intro_mr">Introduction to MapReduce</a></h3>
<p>The best known example of Big Data execution environment is&nbsp;probably Google MapReduce (<em>Dean, J. and Ghemawat, S. (2008).&nbsp;MapReduce:&nbsp;simplified data processing on large clusters.&nbsp;Commun. ACM, 51(1):107-113</em>) (the Google's implementation of the&nbsp;MapReduce&nbsp;programming model) and Hadoop, its open source&nbsp;version (<em>Lam, C. (2011).&nbsp;Hadoop in action.&nbsp;Manning, 1st edition</em>). This environment aims at providing elasticity by allowing the adjustment of resources according to the application, handling&nbsp;errors transparently and ensuring the scalability of the system.</p>
<p>As its name suggests, this programming model is built upon two "simple"&nbsp;abstract functions named&nbsp;Map&nbsp;and&nbsp;Reduce,&nbsp;which are inherited from the classical functional programming paradigms. Users specify the computation in terms of a map (that&nbsp;specify the per-record computation) and a reduce (that specify result aggregation) functions, which meet a few simple&nbsp;requirements. For example, in order to support these, MapReduce requires that the operations performed at the reduce task to be&nbsp;both "associative"&nbsp;and "commutative."&nbsp;This two-stage processing structure is illustrated in Figure&nbsp;2</p>
<p class="rtecenter"><img alt="MapReduce simplified flowchart" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mr.png"></p>
<p class="rtecenter">Figure 2. MapReduce simplified flowchart</p>
<p>We will focus on the Hadoop MapReduce implementation (<em>Lam, C. (2011).&nbsp;Hadoop in action.&nbsp;Manning, 1st editio</em>n) for its wider usage and popularity due to&nbsp;its performance, open source nature, installation facilities and its distributed file system. This fact is quite important to&nbsp;remark, as we may distinguish between MapReduce (the theoretical framework) and Hadoop MapReduce (the world-wide open source implementation). Additionally, we will describe SPARK (<em>Zaharia, M., Chowdhury, M., Das, T., Dave, A., Ma, J., McCauley, M., Franklin,&nbsp;M.~J., Shenker, S., and Stoica, I. (2012).&nbsp;Resilient distributed datasets: A fault-tolerant abstraction for&nbsp;in-memory cluster computing.&nbsp;In 9th USENIX Conference on Networked Systems Design and&nbsp;&nbsp;Implementation, NSDI'12, pages 1-14)</em>, a novel programming model which aims at providing faster response times than Hadoop for iterative-based algorithms.</p>
<h3><img alt="Hadoop" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/hadoop-history.png" style="font-size: 13px; line-height: 20.7999992370605px; width: 188px; height: 180px; float: left;"><a id="hadoop" name="hadoop">Hadoop Ecosystem</a></h3>
<p>The MapReduce framework is based on the fact that most of the information processing tasks consider a similar structure, i.e. the&nbsp;same computation is applied over a large number of records; then, intermediate results are aggregated in some way. As it was&nbsp;previously described, the programmer must specify the Map and Reduce functions within a job. Then, the job usually divides the&nbsp;input dataset into independent subsets that are processed in parallel by the Map tasks. MapReduce sorts the different outputs of&nbsp;the Map tasks which become the inputs that will be processed by the Reduce task. The main components of this programming model,&nbsp;that were previously illustrated in Fig. 1, are the following ones:</p>
<ul><li>The job input is usually stored on a distributed file system. The master node performs a segmentation of the input dataset into independent blocks and distributes them to the worker nodes. Next, each worker node processes the smaller problem,&nbsp;and passes the answer back to its master node. This information is given in terms of \emph{<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mo" id="MathJax-Span-3" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"><</script>key,value<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-5"><span class="mo" id="MathJax-Span-6" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-2">></script> pairs} which form the processing primitives.</li>
<li>The former input <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-7" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-8"><span class="mo" id="MathJax-Span-9" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"><</script>key,value<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-10" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-11"><span class="mo" id="MathJax-Span-12" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-4">></script> pairs are split and distributed among the available <em>Map</em>&nbsp;tasks. Specifically, Map invocations are distributed across multiple machines by automatically partitioning the input data into a set of M splits.&nbsp;The input splits can be processed in parallel by different machines. Then, Map-functions emit a set of intermediate <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-13" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-14"><span class="mo" id="MathJax-Span-15" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-5"><</script>key,values<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-16" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-17"><span class="mo" id="MathJax-Span-18" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-6">></script>&nbsp;pairs as output. Before the execution of a Reduce function, MapReduce groups all intermediate values associated with the same&nbsp;intermediate key (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-19" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-20"><span class="mo" id="MathJax-Span-21" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-7"><</script>key,list(values)<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-22" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-23"><span class="mo" id="MathJax-Span-24" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-8">></script> and transforms them to speed up the computation in the Reduce function.</li>
<li>The intermediate values are supplied to the user's <em>Reduce</em>&nbsp;function via an iterator, which allows to handle lists of&nbsp;values that are too large to fit in memory. In particular, Reduce invocations are distributed by partitioning the intermediate&nbsp;key space into R pieces using a partitioning function (e.g., hash(key) module R). The number of partitions (R) and the&nbsp;partitioning function are specified by the user. Finally, the Reduce-functions generate an arbitrary number of final <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-25" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-26"><span class="mo" id="MathJax-Span-27" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-9"><</script>key,values<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-28" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-29"><span class="mo" id="MathJax-Span-30" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-10">></script>&nbsp;pairs as output.</li>
</ul><p>The whole process can be summarized as follows: the master node collects the answers to all the sub-problems, sorts the Map task&nbsp;outputs by their keys, groups those that have the same key, and shuffles them among the available Reduce tasks using a dynamic&nbsp;scheduling mechanism. In this approach, the runtime assigns Map/Reduce tasks to the available computation resources simplifying&nbsp;the optimal utilization of heterogeneous computational resources while the initial assignment of Map tasks is performed based on&nbsp;the data locality. This approach also provides an automatic load balancing for Map tasks with skewed data or computational&nbsp;distributions.</p>
<p>An illustrative example about how MapReduce works could be finding the average costs per year from a big list of cost records.&nbsp;Each record may be composed by a variety of values, but it at least includes the year and the cost. The Map function extracts&nbsp;from each record the pairs <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-31" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-32"><span class="mo" id="MathJax-Span-33" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-11"><</script> year, cost <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-34" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-35"><span class="mo" id="MathJax-Span-36" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-12">></script> and transmits them as its output. The shuffle stage groups the <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-37" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-38"><span class="mo" id="MathJax-Span-39" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-13"><</script> year, cost <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-40" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-41"><span class="mo" id="MathJax-Span-42" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-14">></script>&nbsp;pairs by its corresponding year, creating a list of costs per year <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-43" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-44"><span class="mo" id="MathJax-Span-45" style="font-family: MathJax_Main;">&lt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&lt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-15"><</script> year, list(cost) <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-46" style="width: 0.996em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.43em 1000.75em 2.422em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-47"><span class="mo" id="MathJax-Span-48" style="font-family: MathJax_Main;">&gt;</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.15em; border-left: 0px solid; width: 0px; height: 0.85em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&gt;</mo></math></span></span><script type="math/tex" id="MathJax-Element-16">></script>. Finally, the Reduce phase performs&nbsp;the average of all the costs contained in the list of each year.</p>
<p>Finally, we must stress the Mahout Machine Learning library (Owen, S., Anil, R., Dunning, T., and Friedman, E. (2011).&nbsp;Mahout in Action.&nbsp;Manning Publications Co., 1st edition). It contains scalable machine&nbsp;learning implementations written in Java and built mainly upon Apache's Hadoop distributed computation project.&nbsp;First of all, we must point out two significant issues: (1) On the one hand, it is just a library. This means that it does not&nbsp;provide a user interface, a prepackaged server, or an installer. It is a simply framework of tools intended to be used and&nbsp;adapted by developers. (2) On the second hand, it is still under development (currently is under version 0.9). It is a quite&nbsp;recent approach and it is far from being thoroughly documented. However, it includes a wide amount of methods and it is&nbsp;continuously in expansion with new DM approaches. Currently, it supports the aforementioned main kind of learning tasks. It&nbsp;addition, it includes dimension reduction techniques, and other miscellaneous approaches, all of which are summarized in Table 1.</p>
<table border="1" cellpadding="1" cellspacing="1" summary="Mahout algorithms"><caption>
<p class="rtecenter">DM tasks and algorithms implemented in the Mahout software tool version 0.9</p>
</caption>
<thead><tr><th scope="col">Type of Task</th>
<th scope="col">List of algorithms</th>
</tr></thead><tbody><tr><td>Classification</td>
<td>Naive Bayes/ Complementary Naive Bayes; Multilayer Perceptron; Random Forest;&nbsp;Logistic Regression; Hidden Markov Models</td>
</tr><tr><td>Clustering</td>
<td>Canopy Clustering; k-Means Clustering; Fuzzy k-Means; Streaming k-Means;&nbsp;Spectral Clustering</td>
</tr><tr><td>Collaborative Filtering</td>
<td>User-Based Collaborative Filtering;&nbsp;Item-Based Collaborative Filtering;&nbsp;Matrix Factorization with Alternating Least Squares;&nbsp;Weighted Matrix Factorization; SVD++; Parallel SGD</td>
</tr><tr><td>Dimension reduction</td>
<td>​Singular Value Decomposition;&nbsp;Stochastic Singular Value Decomposition; Principal Components Analysis; Lanczos algorithm;&nbsp;Topic Models; Latent Dirichlet Allocation</td>
</tr><tr><td>Miscellaneous</td>
<td>Frequent Pattern Mining;&nbsp;RowSimilarityJob - compute pairwise similarities between the rows of a matrix;&nbsp;ConcatMatrices - combine 2 matrices or vectors into a single matrix;&nbsp;Collocations - find co-locations of tokens in text</td>
</tr></tbody></table><p>
In April 2014, Mahout has said goodbye to MapReduce. The justification for this change is two-fold: on the one hand organizational issues, as it was onerous to provide support for scalable ML; on the other hand, technical considerations, as MapReduce is not so well suited for ML, mainly due to<br>
the launching overhead, especially noticeable for iterative algorithms, different quality of implementations, and/or and the unsuitability of some methods to be codified as Map and Reduce operations.</p>
<p>Hence, the future of Mahout is the usage of modern parallel processing systems which offer richer programming models and more efficient executions, while maintaining the underlying HDFS. The answer to these constraints is Apache SPARK (<em>Zaharia, M., Chowdhury, M., Franklin, M.~J., Shenker, S., and Stoica, I.&nbsp;&nbsp;(2010).&nbsp;Spark: Cluster computing with working sets.&nbsp;In HotCloud 2010, pages 1-7</em>)&nbsp;, which will be also described in detail in the following section. In this way, future implementations will use the DSL linear algebraic operations following Scala &amp; Spark Bindings. These are basically similar to R (Matlab)-like semantics, allowing automatic optimization and parallelization of programs.</p>
<p>&nbsp;</p>
<h3><a href="http://spark.apache.org/" style="font-size: 13px; line-height: 20.7999992370605px;"><img alt="" height="124" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/spark-logo(1).png" style="float: left;" width="232"></a><a id="spark" name="spark">Apache Spark framework</a></h3>
<p>We have stressed the goodness of MapReduce as a powerful solution designed to solve different kinds of Big Data problems. However,&nbsp;it is not a panacea: there are some scenarios in which this functional programming model does not achieve the expected performance, and therefore&nbsp;alternative solutions must be chosen. &nbsp;In particular, among all possible deficiencies of MapReduce, the greatest critic reported is the implementation of&nbsp;<em>iterative jobs</em>&nbsp;(<em>Lin, J. (2013).&nbsp;Mapreduce is good enough?&nbsp;Big Data, 1(1):BD28-BD37</em>). In fact, many common machine learning algorithms apply a function repeatedly to the same&nbsp;dataset to optimize a parameter. The input to any Hadoop MapReduce job is stored on the HDFS. Hence, whenever a job is executed,&nbsp;the input has to be reload the data from disk every time. This is done regardless of how much of the input has changed from the&nbsp;previous iterations, incurring in a significant performance penalty.</p>
<p>In this sense, <strong>SPARK</strong>&nbsp;(<em>Zaharia, M., Chowdhury, M., Franklin, M.~J., Shenker, S., and Stoica, I.&nbsp;&nbsp;(2010).&nbsp;Spark: Cluster computing with working sets.&nbsp;In HotCloud 2010, pages 1-7</em>) and <strong>SPARK2</strong> (<em>Zaharia, M., Chowdhury, M., Das, T., Dave, A., Ma, J., McCauley, M., Franklin,&nbsp;M.~J., Shenker, S., and Stoica, I. (2012).&nbsp;Resilient distributed datasets: A fault-tolerant abstraction for&nbsp;&nbsp; in-memory cluster computing.&nbsp;In 9th USENIX Conference on Networked Systems Design and&nbsp;Implementation, NSDI'12, pages 1-14</em>) are developed to overcome data reuse across multiple computations. It supports iterative applications, while retaining the scalability and fault tolerance of MapReduce, supporting in-memory processes. Among them, we outline some of most important of those operators:</p>
<ul><li><strong>Filter</strong>(func) Return a new dataset formed by selecting those elements of the source on which the function agrees.</li>
<li><strong>SortByKey</strong>([ascending], [numTasks]): A distributed version of sequential sorting. It sorts by key the values in each partition and then sorts the partitions.</li>
</ul><p>With this aim, the authors include a new abstraction model called Resilient Distributed Datasets (RDDs), which are simply a distributed collection of items. RDDs are fault-tolerant, parallel data structures that let users explicitly persist intermediate results in memory, control their partitioning to optimize data placement. In a nutshell, it provides a restricted form of shared memory based on coarse-grained transformations rather than fine-grained updates to shared state. RDDs can either be cached in memory or materialized from permanent storage when needed (based on lineage, which is the sequence of transformations applied to the data). Additionally, Spark provides a wider range of primitives than exposed by MapReduce framework. Those extend the idea of MapReduce to implement more complex operations on distributed data.</p>
<p>Similar to Mahout for Hadoop (<em>Owen, S., Anil, R., Dunning, T., and Friedman, E. (2011).&nbsp;Mahout in Action.&nbsp;Manning Publications Co., 1st edition</em>), Spark implements a Machine Learning library known as MLlib, included within the MLBase platform (<em>Kraska, T., Talwalkar, A., J.Duchi, Griffith, R., Franklin, M., and Jordan, M.&nbsp;(2013).&nbsp;Mlbase: A distributed machine learning system.&nbsp;In Conference on Innovative Data Systems Research, pages 1-7</em>). MLlib currently supports common types of machine learning problem settings, as well as associated tests and data generators. It includes binary classification, regression, clustering and collaborative filtering, as well as an underlying gradient descent optimization primitive.</p>
<h2><a id="Preprocessing" name="Preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/bigdata_05_3.png" style="width: 175px; height: 129px; float: left;">Big Data Preprocessing</a></h2>
<p class="rteindent4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. <a href="http://sci2s.ugr.es/BigData#intro_dp">Introduction to Data Preprocessing</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. <a href="http://sci2s.ugr.es/BigData#FS">Feature Selection</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. <a href="http://sci2s.ugr.es/BigData#FW">Feature Weighting</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4. <a href="http://sci2s.ugr.es/BigData#discr">Discretization</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5. <a href="http://sci2s.ugr.es/BigData#PG">Prototype Generation</a></p>
<h3><a id="intro_dp" name="intro_dp">Introduction to Data Preprocessing</a></h3>
<p>Data preprocessing is a crucial research topic in Data Mining (DM) since most real-world databases are highly influenced by negative elements such as the presence of noise, missing values, inconsistent and superfluous data. A complete Website with information regarding this topic can be accessed through the Webpage associated to the book&nbsp;S.&nbsp;García, J.&nbsp;Luengo, and <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, Data Preprocessing in Data Mining. Springer, (2015) clicking on the following&nbsp;figure:</p>
<p class="rtecenter">&nbsp;<a href="http://sci2s.ugr.es/books/data-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo data-preprocessing-small.png" style="width: 125px; height: 188px;"></a></p>
<p>The reduction of data is also an essential task especially when dealing with large data sets, focusing on the selection or extraction of the most informative features or instances in the data.. During the last few decades, the dimensionality of datasets employed in DM tasks has significantly increased. This presents an unprecedented challenge for researchers in these areas, since the existing algorithms not always respond in an adequate time when dealing with this new extremely high dimensions (both in number of features and instances). Exceptional technologies, paradigms and algorithms are thus needed to efficiently process these large quantities of data to obtain information, within tolerable elapsed times.</p>
<h3><a id="FS" name="FS">Feature Selection</a></h3>
<p>With the advent of extremely high dimensional datasets, dimensionality reduction techniques are becoming mandatory. Among many techniques, feature selection is growing in interest as an important tool to identify relevant features on huge datasets; both in number of instances and features. From the beginning, data scientists have generally focused on only one side of Big Data, which early days refers to the huge number of instances; paying less attention to the feature side. Big Dimensionality (<em>Zhai Y, Ong Y, Tsang IW (2014) The emerging “big dimensionality”. IEEE Comp Int Mag 9(3):14–26</em>), though, calls for new feature selection strategies and methods that are able to deal with the feature explosion problem. It has been captured in many of the most famous dataset repositories in computational intelligence (like UCI or libSVM), where the majority of the new added datasets present a humongous dimensionality (in order of millions of features).</p>
<p>Isolating high value features from the raw set of features (potentially irrelevant, redundant and noisy), while maintaining the requirements in measurement and storage, is one of the most important tasks in Big Data research. In this field, we have developed some software packages in order to solve the aforementioned problem.</p>
<ul><li>
<p><strong>Evolutionary Feature Selection model based on MapReduce (MR-EFS</strong>)</p>
</li>
</ul><p>This implements&nbsp;a feature selection algorithm based on evolutionary computation that&nbsp;uses the MapReduce paradigm to obtain subsets of features from big datasets. The algorithm&nbsp;decomposes the original dataset in blocks of instances to learn from them in the map phase; then,&nbsp;the reduce phase merges the obtained partial results into a final vector of feature weights, which&nbsp;allows a flexible application of the feature selection procedure using a threshold to determine the&nbsp;selected subset of features.</p>
<p>The former software is published in the following reference:</p>
<p><strong><a href="http://sci2s.ugr.es/members#DPeralta">D. Peralta</a>,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>,&nbsp;<a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong>&nbsp;<em>Evolutionary Feature Selection for Big Data Classification: A&nbsp;MapReduce Approach</em>. Mathematical Problems in Engineering, vol. 2015, Article ID 246139, 11 pages, 2015, doi: <a href="http://www.hindawi.com/journals/mpe/2015/246139/">10.1155/2015/246139</a> <a href="http://sci2s.ugr.es/sites/default/files/2015-hindawi-peralta.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<p><a href="https://github.com/triguero/MR-EFS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 90px; height: 48px;"></a>&nbsp;<a href="https://github.com/triguero/MR-EFS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mr_efs.png" style="width: 216px; height: 56px;"></a></p>
<ul><li><strong>An Information Theoretic Feature Selection Framework for Spark</strong></li>
</ul><p>This implements FS on Spark for its application on Big Data problems. This package contains a generic implementation of greedy Information Theoretic Feature Selection methods. The implementation is based on the common theoretic framework presented in (<em>Peng, H.C., Long, F., and Ding, C., "Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy," IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 27, No. 8, pp.&nbsp;1226–1238, 2005</em>). Implementations of mRMR, ICAP, JMI and other commonly used FS filters are provided. The journal publication for this package is under revision process.</p>
<p><a href="https://github.com/sramirez/spark-infotheoretic-feature-selection"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;&nbsp;<a href="https://github.com/sramirez/spark-infotheoretic-feature-selection"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/spark_fs.png" style="width: 492px; height: 65px;"></a> &nbsp;<a href="http://spark-packages.org/package/sramirez/spark-infotheoretic-feature-selection"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/spark-logo(1).png" style="width: 93px; height: 50px;"></a></p>
<ul><li><strong>Fast-mRMR: an optimal implementation of minimum Redundancy Maximum Relevance algorithm:</strong></li>
</ul><p>This is an improved implementation of the classical feature selection method: minimum Redundancy and Maximum Relevance (mRMR); presented by Peng in (<em>Hanchuan Peng, Fuhui Long, and Chris Ding "Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy," IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 27, No. 8, pp.1226-1238, 2005.</em>). This includes several optimizations such as: cache marginal probabilities, accumulation of redundancy (greedy approach) and a data-access by columns.</p>
<p><a href="https://github.com/sramirez/fast-mRMR"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/sramirez/fast-mRMR"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mRMR.png" style="width: 250px; height: 66px;"></a></p>
<h3><a id="FW" name="FW">Feature Weighting</a></h3>
<p>
Feature weighting is a feature importance ranking technique where weights, not only ranks, are obtained. When successfully applied relevant features are attributed a high weight value, whereas irrelevant features are given a weight value close to zero. Feature weighting can be used not only to improve classification accuracy but also to discard features with weights below a certain threshold value and thereby increase the resource efficiency of the classifier.</p>
<p>To deal with the aforementioned scalability problems, we have developed the software described below:</p>
<ul><li><strong>Random OverSampling and Evolutionary Feature Weighting for Random Forest (ROSEFW-RF)</strong>.</li>
</ul><p>This includes a feature weighting algorithm based on evolutionary computation that uses the MapReduce paradigm to obtain subsets of features from big datasets. The algorithm decomposes the original dataset in blocks of instances to learn from them in the map phase; then, the reduce phase merges the obtained partial results into a final vector of feature weights, which allows a flexible application of the feature selection procedure using a threshold to determine the selected subset of features.</p>
<p>This work has been published in the following reference:</p>
<p><strong>I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, J. Bacardit,&nbsp;<a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.&nbsp;</strong><em>ROSEFW-RF: The winner algorithm for the ECBDL'14 Big Data Competition: An extremely imbalanced big data bioinformatics problem.</em>&nbsp;Knowledge-Based Systems 87 (2015) 69-79.&nbsp;doi: <a href="http://www.sciencedirect.com/science/article/pii/S0950705115002130">10.1016/j.knosys.2015.05.027</a>&nbsp; <a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-Knosys-triguero_rosefw-RF.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<p><a href="https://github.com/triguero/ROSEFW-RF"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a><a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-Knosys-triguero_rosefw-RF.pdf">&nbsp;</a><a href="https://github.com/triguero/ROSEFW-RF"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/rosefw.png" style="width: 252px; height: 67px;"></a></p>
<h3><a id="discr" name="discr">Discretization</a></h3>
<p>Discretization is one of the most important tasks in data mining process, aimed at simplifying and reducing continuous-valued data in large datasets. In spite of the great interest in this reduction mechanism, only a few simple discretization techniques have been implemented in the literature for Big Data. Among its main benefits, discretization causes in learning methods remarkable improvements in learning speed and accuracy. Although most of real-world problems often imply numerical attributes, many algorithms can only handle categorical attributes, for example some feature selection methods (which are relevant in the Big Data picture).</p>
<p>Classical discretization methods are not expected to scale well when managing huge data -both in terms of features and instances- so that its application can be undermined or even become impracticable. To solve that, we have developed a software package described below:</p>
<ul><li><strong>Distributed Minimum Description Length Discretizer for Spark</strong></li>
</ul><p>This package implements Fayyad's discretizer <em>(Fayyad, U., &amp; Irani, K. (1993). "Multi-interval discretization of continuous-valued attributes for classification learning."</em>) based on Minimum Description Length Principle (MDLP) in order to treat non discrete datasets from a distributed perspective. We have developed a distributed version from the original one performing some important changes.</p>
<p><a href="https://github.com/sramirez/spark-MDLP-discretization"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/sramirez/spark-MDLP-discretization"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mdlp.png" style="width: 396px; height: 67px;"></a> &nbsp;<a href="http://spark-packages.org/package/sramirez/spark-MDLP-discretization"><img alt="" height="50" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/spark-logo(1).png" width="93"></a></p>
<p>This work has been published in the following references:</p>
<ul><li><strong><a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, H. Mouriño-Talin, D. Martínez-Rego, V. Bolón, A. Alonso-Betanzos, J.M. Benitez, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong> <em>"Distributed Entropy Minimization Discretizer for Big Data Analysis under Apache Spark", </em>The 9th IEEE International Conference on Big Data Science and Engineering (IEEE BigDataSE-15), Volume 2; Helsinki (Finland), 33-40, August 20-22, 2015<em>.</em> doi:<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7345472">10.1109/Trustcom.2015.559</a><a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-ramirez-distributed.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
<li><strong><a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, H. Mouriño Talín, D. Martínez-Rego, V. Bolón-Canedo, A. Alonso-Betanzos, J. M. Benítez, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. </strong>Data discretization: taxonomy and big data challenge. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 6:1 (2016) 5-21. doi: <a href="http://dx.doi.org/10.1002/widm.1173">10.1002/widm.1173</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1996_2015-sramirez-taxonomy.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
</ul><h3><a id="PG" name="PG">Prototype Generation</a></h3>
<p>Prototype Reduction (PR) techniques (<em>I. Triguero, J. Derrac, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, A taxonomy and experimental study on prototype generation for nearest neighbor classification, IEEE Trans. Syst., Man, Cybern. Part C. Appl. Rev. 42 (1) (2012) 86–100.</em>), which are instance reduction methods that aim to improve the classification capabilities of the Nearest Neighbor rule (NN). These techniques may select instances from the original data set, or build new artificial prototypes, to form a resulting set of prototypes that better adjusts the decision boundaries between classes in NN classification. The main problems found to deal with large-scale data are the following:</p>
<ul><li>Runtime: The complexity of PR models is O((n D)^2)  or higher, where n is the number of instances and D the number of features. Although these techniques are only applied once, if this process takes too long, its application could become inoperable for real applications.</li>
<li>Memory consumption: Most of PR methods need to store in the main memory many partial calculations, intermediate solutions, and/or also the entire dataset. When the dataset is too big, it could easily exceed the available RAM memory.</li>
</ul><p>In this field, we have developed a MapReduce-based framework for PR based on the stratification procedure:</p>
<ul><li>
<p><strong>I. Triguero, <a href="http://sci2s.ugr.es/members#DPeralta">D. Peralta</a>, J. Bacardit, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. </strong><em>MRPR: A MapReduce Solution for Prototype Reduction in Big Data Classification. </em>Neurocomputing 150 (2015), 331-345. doi: <a href="http://dx.doi.org/10.1016/j.neucom.2014.04.078">10.1016/j.neucom.2014.04.078</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1769_2015-Neurocomputing-MRPR-A%20MapReduce%20solution%20for%20prototype%20reduction%20in%20big%20data%20classification.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></p>
</li>
<li>
<p><strong>I. Triguero, <a href="http://sci2s.ugr.es/members#DPeralta">D. Peralta</a>, J. Bacardit, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. <em>A Combined MapReduce-Windowing Two-Level Parallel Scheme for Evolutionary Prototype Generation</em>. In Proceedings on the WCCI 2014 IEEE World Congress on Computational Intelligence, IEEE Congress on Evolutionary Computation CEC'2014, Beijing (China), 6-11 July, pp. 3036-3043, 2014. doi: <a href="http://dx.doi.org/10.1109/CEC.2014.6900490">10.1109/CEC.2014.6900490 </a><a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/06900490.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
</li>
</ul><p><a href="https://github.com/triguero/MRPR"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/triguero/MRPR"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mpmr.png" style="width: 199px; height: 68px;"></a></p>
<p>This model was later enhanced with a windowing mechanism that accelerate the evolutionary prototype generation process.</p>
<ul><li><strong>I. Triguero, <a href="http://sci2s.ugr.es/members#DPeralta">D. Peralta</a>, J. Bacardit, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. <em>A Combined MapReduce-Windowing Two-Level Parallel Scheme for Evolutionary Prototype Generation</em>. In Proceeding on the WCCI 2014 IEEE World Congress on Computational Intelligence, IEEE Congress on Evolutionary Computation CEC'2014, Beijing (China), 6-11 July, pp. 3036-3043, 2014. <a href="http://dx.doi.org/10.1109/CEC.2014.6900490">doi: 10.1109/CEC.2014.6900490</a></li>
</ul><p><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/bigdata_01_3.png" style="width: 175px; height: 114px; float: left;"></p>
<h2 class="rtejustify"><a name="Imbalanced Big Data" id="Imbalanced Big Data">Imbalanced Big Data classification</a></h2>
<p class="rteindent4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. <a href="http://sci2s.ugr.es/BigData#imb_intro">Introduction to imbalanced datasets</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. <a href="http://sci2s.ugr.es/BigData#imb_approach">Analysis of preprocessing approaches for imbalanced big data classification</a><br>
&nbsp; &nbsp; &nbsp; &nbsp;3. <a href="http://sci2s.ugr.es/BigData#oversampling">Analysis of the oversampling rate for extremely imbalanced big data</a><br>
&nbsp; &nbsp; &nbsp;&nbsp; 4. <a href="http://sci2s.ugr.es/BigData#eus">Evolutionary undersampling for imbalanced big data</a></p>
<p class="rteindent4">&nbsp;</p>
<h3><a id="imb_intro" name="imb_intro">Introduction to imbalanced datasets</a></h3>
<p>In the classification problem field, the scenario of imbalanced datasets appears frequently. The main property of this type of classification problem is that the examples of one class significantly outnumber the examples of the other one (<em>V. López, A. Fernandez, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, V. Palade,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.&nbsp;An Insight into Classification with Imbalanced Data: Empirical Results and Current Trends on Using Data Intrinsic Characteristics.&nbsp;Information Sciences 250 (2013) 113-141</em>). The minority class usually represents the most important concept to be learned, and it is difficult to identify it since it might be associated with exceptional and significant cases, or because the data acquisition of these examples is costly. In most cases, the imbalanced class problem is associated to binary classification, but the multi-class problem often occurs and, since there can be several minority classes, it is more difficult to solve (<em>A. Fernández, V. López, M. Galar, M.J. del Jesus, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, Analysing the classification of imbalanced data-sets with multiple classes: binarization techniques and ad-hoc approaches, Knowledge-Based Systems 42 (2013) 97–110</em>).</p>
<p>Since most of the standard learning algorithms consider a balanced training set, this may generate suboptimal classification models, i.e. a good coverage of the majority examples, whereas the minority ones are misclassified frequently. Therefore, those algorithms, which obtain a good behavior in the framework of standard classification, do not necessarily achieve the best performance for imbalanced datasets (<em>A. Fernandez, <a href="http://sci2s.ugr.es/members#SGarcia"></a><a href="http://sci2s.ugr.es/members#SGarcia">S. García</a>, <a href="http://sci2s.ugr.es/members#JLuengo">J. Luengo</a>, E. Bernadó-Mansilla, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, Genetics-based machine learning for rule induction: state of the art, taxonomy and comparative study, IEEE Transactions on Evolutionary Computation 14 (6) (2010) 913–941</em>). There are several reasons behind this behavior:</p>
<ul><li>The use of global performance measures for guiding the learning process, such as the standard accuracy rate, may provide an advantage to the majority class.</li>
<li>Classification rules that predict the positive class are often highly specialized and thus their coverage is very low, hence they are discarded in favor of more general rules, i.e. those that predict the negative class.</li>
<li>Very small clusters of minority class examples can be identified as noise, and therefore they could be wrongly discarded by the classifier. On the contrary, few real noisy examples can degrade the identification of the minority class, since it has fewer examples to train with.</li>
</ul><p>A large number of approaches have been proposed to deal with the class imbalance problem (<em>H. He, E.A. Garcia, Learning from imbalanced data, IEEE Transactions on Knowledge and Data Engineering 21 (9) (2009) 1263–1284</em>). These approaches can be categorized into two groups: the internal approaches that create new algorithms or modify existing ones to take the class-imbalance problem into consideration and external approaches that preprocess the data in order to diminish the effect of their class imbalance. Furthermore, cost-sensitive learning solutions incorporating both the data (external) and algorithmic level (internal) approaches assume higher misclassification costs for samples in the minority class and seek to minimize the high cost errors). Ensemble methods are also frequently adapted to imbalanced domains (<em>M. Galar, A. Fernández, E. Barrenechea, H. Bustince,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>,&nbsp;A review on ensembles for class imbalance problem: bagging, boosting and hybrid based approaches.&nbsp;IEEE Transactions on Systems, Man, and Cybernetics – part C: Applications and Reviews&nbsp;42:4 (2012) 463-484</em>), either by modifying the ensemble learning algorithm at the data-level approach to preprocess the data before the learning stage of each classifier.</p>
<p>In the specialized literature, we can find some papers about resampling techniques studying the effect of changing the class distribution in order to deal with imbalanced datasets.&nbsp;Those works have proved empirically that applying a preprocessing step in order to balance the class distribution is usually an useful solution (<em>G.E.A.P.A. Batista, R.C. Prati, M.C. Monard, A study of the behaviour of several methods for balancing machine learning training data, SIGKDD Explorations 6 (1) (2004) 20–29</em>). Furthermore, the main advantage of these techniques is that they are independent of the underlying classifier.</p>
<p>Resampling techniques can be categorized into three groups or families:</p>
<ol><li>Undersampling methods, which create a subset of the original dataset by eliminating instances (usually majority class instances).</li>
<li>Oversampling methods, which create a superset of the original dataset by replicating some instances or creating new instances from existing ones.</li>
<li>Hybrids methods, which combine both sampling approaches from above.</li>
</ol><p>Within these families of methods, the simplest preprocessing techniques are non-heuristic methods such as <strong>random undersampling</strong> and <strong>random oversampling</strong>.&nbsp;Their working procedure is very simple:&nbsp;they are devoted to randomly&nbsp;remove examples of the majority class,&nbsp;or&nbsp;replicate&nbsp;examples from the minority class. This process is carried out only&nbsp;in the training set with aims at rebalancing the data distribution to the 50%.&nbsp;In the first case, i.e. random undersampling,&nbsp;the major drawback is that it can discard potentially useful data, that could be important for the learning process. For random oversampling, several authors agree that this method can increase the likelihood of occurring overfitting, since it makes exact copies of existing instances.</p>
<p>In order to deal with the mentioned problems, more sophisticated methods have been proposed. Among them, the "Synthetic Minority Oversampling TEchnique" (SMOTE) (<em>N.V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, SMOTE: synthetic minority over-sampling technique, Journal of Artificial Intelligent Research 16 (2002) 321–357</em>) has become one of the most renowned approaches in this area. In brief, its main idea is to create new minority class examples by interpolating several minority class instances that lie together for oversampling the training set.</p>
<p>With this technique, the positive class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the k minority class nearest neighbors. Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen. This process is illustrated in Figure&nbsp;3, where xi is the selected point, xi1 to xi4 are some selected nearest neighbors and r1 to r4 the synthetic data points created by the randomized interpolation.</p>
<p class="rtecenter"><img alt="An illustration of how to create the synthetic data points in the SMOTE algorithm" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/smote.png" style="height: 203px; width: 300px;"></p>
<p class="rtecenter">Figure 3. An illustration of how to create the synthetic data points in the SMOTE algorithm</p>
<p>Regarding undersampling, most of the proposed approaches are based on data cleaning techniques. Some representative works in this area include the Wilson's edited nearest neighbor (ENN)&nbsp;rule (<em>D.L. Wilson, Asymptotic properties of nearest neighbor rules using edited data, IEEE Transactions on Systems, Man and Cybernetics 2 (3) (1972) 408–421. doi: 10.1109/TSMC.1972.4309137</em>), which removes examples that differ from two of its three nearest neighbors, the one-sided selection (OSS) (<em>M. Kubat, S. Matwin, Addressing the curse of imbalanced training sets: one-sided selection, in: Proceedings of the 14th International Conference on Machine Learning (ICML’97), 1997, pp. 179–186</em>.), an integration method between the condensed nearest neighbor rule (<em>P.E. Hart, The condensed nearest neighbor rule, IEEE Transactions on Information Theory 14 (1968) 515–516. doi: 10.1109/TIT.1968.1054155) and Tomek Links (I. Tomek, Two modifications of CNN, IEEE Transactions on Systems Man and Communications 6 (1976) 769–772. doi: 10.1109/TSMC.1976.4309452</em>) and the neighborhood cleaning rule (<em>J. Laurikkala, Improving identification of difficult small classes by balancing class distribution, in: Proceedings of the 8th Conference on AI in Medicine in Europe: Artificial Intelligence Medicine (AIME’01), 2001, pp. 63–66.</em>), which is based on the ENN technique.&nbsp;</p>
<p>On the other hand, cost-sensitive learning takes into account the variable cost of a misclassification with respect to the different classes (<em>P. Domingos, Metacost: a general method for making classifiers cost–sensitive, in: Proceedings of the 5th International Conference on Knowledge Discovery and Data Mining (KDD’99), 1999, pp. 155–164)</em>. In this case, a cost matrix codifies the penalties C(i,j) of classifying examples of one class i as a different one j.&nbsp;These misclassification cost values can be given by domain experts, or can be learned via other approaches (<em>Y. Sun, M.S. Kamel, A.K.C. Wong, Y. Wang, Cost-sensitive boosting for classification of imbalanced data, Pattern Recognition 40 (12) (2007) 3358–3378.;&nbsp;Y. Sun, A.K.C. Wong, M.S. Kamel, Classification of imbalanced data: a review, International Journal of Pattern Recognition and Artificial Intelligence 23 (4) (2009) 687–719</em>). Specifically, when dealing with imbalanced problems, it is usually more interesting to recognize the positive instances rather than the negative ones. Therefore, the cost when misclassifying a positive instance must be higher than the cost of misclassifying a negative one, i.e. C(+,-) &gt; C(-,+).</p>
<p>Given the cost matrix, an example should be classified into the class that has the lowest expected cost, which is known as the minimum expected cost principle. The expected cost R(i|x) of classifying an instance x into class i (by a classifier) can be expressed as:</p>
<p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-49" style="width: 14.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.976em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.058em 1011.85em 3.663em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-52" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-53" style="font-family: MathJax_Math-italic;">i</span><span class="texatom" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="mo" id="MathJax-Span-56" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-57" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-58" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-59" style="font-family: MathJax_Main; padding-left: 0.251em;">=</span><span class="munderover" id="MathJax-Span-60" style="padding-left: 0.251em;"><span style="display: inline-block; position: relative; width: 1.43em; height: 0px;"><span style="position: absolute; clip: rect(2.857em 1001.37em 4.594em -999.997em); top: -3.967em; left: 0em;"><span class="mo" id="MathJax-Span-61" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span><span style="position: absolute; clip: rect(3.291em 1000.31em 4.408em -999.997em); top: -2.913em; left: 0.561em;"><span class="texatom" id="MathJax-Span-62"><span class="mrow" id="MathJax-Span-63"><span class="mi" id="MathJax-Span-64" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span></span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span></span></span><span class="mi" id="MathJax-Span-65" style="font-family: MathJax_Math-italic; padding-left: 0.189em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-66" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-67" style="font-family: MathJax_Math-italic;">j</span><span class="texatom" id="MathJax-Span-68"><span class="mrow" id="MathJax-Span-69"><span class="mo" id="MathJax-Span-70" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-71" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-72" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-73" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-74" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-75" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-76" style="font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-77" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-78" style="font-family: MathJax_Math-italic; padding-left: 0.189em;">j</span><span class="mo" id="MathJax-Span-79" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.688em; border-left: 0px solid; width: 0px; height: 3.004em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>R</mi><mo stretchy="false">(</mo><mi>i</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>j</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>j</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-17">R(i|x)=\sum_{j}P(j|x)·C(i,j)</script></p>
<p>where P(j|x) is the probability estimation of classifying an instance into class j. That is, the classifier will classify an instance x into positive class if and only if:</p>
<p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2264;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-80" style="width: 37.968em; display: inline-block;"><span style="display: inline-block; position: relative; width: 30.586em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.244em 1030.46em 2.609em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-81"><span class="mi" id="MathJax-Span-82" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-83" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-84" style="font-family: MathJax_Main;">0</span><span class="texatom" id="MathJax-Span-85"><span class="mrow" id="MathJax-Span-86"><span class="mo" id="MathJax-Span-87" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-88" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-89" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-90" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-91" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-92" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-93" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-94" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-95" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-96" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-97" style="font-family: MathJax_Main; padding-left: 0.251em;">+</span><span class="mi" id="MathJax-Span-98" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-99" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-100" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-101"><span class="mrow" id="MathJax-Span-102"><span class="mo" id="MathJax-Span-103" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-104" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-105" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-106" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-107" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-108" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-109" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-110" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-111" style="font-family: MathJax_Main; padding-left: 0.189em;">1</span><span class="mo" id="MathJax-Span-112" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-113" style="font-family: MathJax_Main; padding-left: 0.251em;">≤</span><span class="mi" id="MathJax-Span-114" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-115" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-116" style="font-family: MathJax_Main;">0</span><span class="texatom" id="MathJax-Span-117"><span class="mrow" id="MathJax-Span-118"><span class="mo" id="MathJax-Span-119" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-120" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-121" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-122" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-123" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-124" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-125" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-126" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-127" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-128" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-129" style="font-family: MathJax_Main; padding-left: 0.251em;">+</span><span class="mi" id="MathJax-Span-130" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-131" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-132" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-133"><span class="mrow" id="MathJax-Span-134"><span class="mo" id="MathJax-Span-135" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-136" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-137" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-138" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-139" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-140" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-141" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-142" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-143" style="font-family: MathJax_Main; padding-left: 0.189em;">1</span><span class="mo" id="MathJax-Span-144" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.381em; border-left: 0px solid; width: 0px; height: 1.388em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo stretchy="false">(</mo><mn>0</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>≤</mo><mi>P</mi><mo stretchy="false">(</mo><mn>0</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-18">P(0|x)·C(1,0)+P(1|x)·C(1,1) \le P(0|x) · C(0,0)+P(1|x)·C(0,1)</script></p>
<p>or, which is equivalent:</p>
<p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2264;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-145" style="width: 29.346em; display: inline-block;"><span style="display: inline-block; position: relative; width: 23.638em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.244em 1023.51em 2.609em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-146"><span class="mi" id="MathJax-Span-147" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-148" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-149" style="font-family: MathJax_Main;">0</span><span class="texatom" id="MathJax-Span-150"><span class="mrow" id="MathJax-Span-151"><span class="mo" id="MathJax-Span-152" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-153" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-154" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-155" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mo" id="MathJax-Span-156" style="font-family: MathJax_Main; padding-left: 0.251em;">(</span><span class="mi" id="MathJax-Span-157" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-158" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-159" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-160" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-161" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-162" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-163" style="font-family: MathJax_Main; padding-left: 0.251em;">−</span><span class="mi" id="MathJax-Span-164" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-165" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-166" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-167" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-168" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-169" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-170" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-171" style="font-family: MathJax_Main; padding-left: 0.251em;">≤</span><span class="mi" id="MathJax-Span-172" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-173" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-174" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-175"><span class="mrow" id="MathJax-Span-176"><span class="mo" id="MathJax-Span-177" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-178" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-179" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-180" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-181" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-182" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-183" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-184" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-185" style="font-family: MathJax_Main; padding-left: 0.189em;">1</span><span class="mo" id="MathJax-Span-186" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-187" style="font-family: MathJax_Main; padding-left: 0.251em;">−</span><span class="mi" id="MathJax-Span-188" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-189" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-190" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-191" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-192" style="font-family: MathJax_Main; padding-left: 0.189em;">1</span><span class="mo" id="MathJax-Span-193" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.381em; border-left: 0px solid; width: 0px; height: 1.388em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo stretchy="false">(</mo><mn>0</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mo stretchy="false">(</mo><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>C</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>≤</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>C</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-19">P(0|x)·(C(1,0)-C(0,0)) \le P(1|x)(C(0,1)-C(1,1)</script></p>
<p>Therefore, any given cost-matrix can be converted to one with C(0,0) = C(1,1) = 0. Under this assumption, the classifier will classify an instance x into positive class if and only if:</p>
<p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2264;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#xB7;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-194" style="width: 18.179em; display: inline-block;"><span style="display: inline-block; position: relative; width: 14.643em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.244em 1014.52em 2.609em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-195"><span class="mi" id="MathJax-Span-196" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-197" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-198" style="font-family: MathJax_Main;">0</span><span class="texatom" id="MathJax-Span-199"><span class="mrow" id="MathJax-Span-200"><span class="mo" id="MathJax-Span-201" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-202" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-203" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-204" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-205" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-206" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-207" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-208" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-209" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-210" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-211" style="font-family: MathJax_Main; padding-left: 0.251em;">≤</span><span class="mi" id="MathJax-Span-212" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-213" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-214" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-215"><span class="mrow" id="MathJax-Span-216"><span class="mo" id="MathJax-Span-217" style="font-family: MathJax_Main;">|</span></span></span><span class="mi" id="MathJax-Span-218" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-219" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-220" style="font-family: MathJax_Main; padding-left: 0.251em;">⋅</span><span class="mi" id="MathJax-Span-221" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-222" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-223" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-224" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-225" style="font-family: MathJax_Main; padding-left: 0.189em;">1</span><span class="mo" id="MathJax-Span-226" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.381em; border-left: 0px solid; width: 0px; height: 1.388em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>P</mi><mo stretchy="false">(</mo><mn>0</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo>≤</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mo stretchy="false">)</mo><mo>·</mo><mi>C</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-20">P(0|x)·C(1,0) \le P(1|x)·C(0,1)</script></p>
<p>As P(0|x) = 1 - P(1|x), we can obtain a threshold p* for the classifier to classify an instance x into positive if P(1|x) &gt; p*, where</p>
<p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msup&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-227" style="width: 19.73em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.884em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(0.499em 1015.88em 3.353em -999.997em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-228"><span class="msubsup" id="MathJax-Span-229"><span style="display: inline-block; position: relative; width: 0.934em; height: 0px;"><span style="position: absolute; clip: rect(3.353em 1000.5em 4.346em -999.997em); top: -3.967em; left: 0em;"><span class="mi" id="MathJax-Span-230" style="font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span><span style="position: absolute; top: -4.401em; left: 0.499em;"><span class="mo" id="MathJax-Span-231" style="font-size: 70.7%; font-family: MathJax_Main;">∗</span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span></span></span><span class="mo" id="MathJax-Span-232" style="font-family: MathJax_Main; padding-left: 0.251em;">=</span><span class="mfrac" id="MathJax-Span-233" style="padding-left: 0.251em;"><span style="display: inline-block; position: relative; width: 7.385em; height: 0px; margin-right: 0.127em; margin-left: 0.127em;"><span style="position: absolute; clip: rect(3.043em 1002.92em 4.408em -999.997em); top: -4.712em; left: 50%; margin-left: -1.486em;"><span class="mrow" id="MathJax-Span-234"><span class="mi" id="MathJax-Span-235" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-236" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-237" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-238" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-239" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-240" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span><span style="position: absolute; clip: rect(3.043em 1007.2em 4.408em -999.997em); top: -3.223em; left: 50%; margin-left: -3.657em;"><span class="mrow" id="MathJax-Span-241"><span class="mi" id="MathJax-Span-242" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-243" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-244" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-245" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-246" style="font-family: MathJax_Main; padding-left: 0.189em;">0</span><span class="mo" id="MathJax-Span-247" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-248" style="font-family: MathJax_Main; padding-left: 0.251em;">−</span><span class="mi" id="MathJax-Span-249" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span><span class="mo" id="MathJax-Span-250" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-251" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-252" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-253" style="font-family: MathJax_Main; padding-left: 0.189em;">1</span><span class="mo" id="MathJax-Span-254" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span><span style="position: absolute; clip: rect(0.81em 1007.38em 1.244em -999.997em); top: -1.3em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 7.385em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.058em;"></span></span></span></span><span class="mo" id="MathJax-Span-255" style="font-family: MathJax_Main; padding-left: 0.251em;">=</span><span class="mfrac" id="MathJax-Span-256" style="padding-left: 0.251em;"><span style="display: inline-block; position: relative; width: 4.532em; height: 0px; margin-right: 0.127em; margin-left: 0.127em;"><span style="position: absolute; clip: rect(3.105em 1001.49em 4.159em -999.997em); top: -4.65em; left: 50%; margin-left: -0.741em;"><span class="mrow" id="MathJax-Span-257"><span class="mi" id="MathJax-Span-258" style="font-family: MathJax_Math-italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mi" id="MathJax-Span-259" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span><span style="position: absolute; clip: rect(3.105em 1004.41em 4.221em -999.997em); top: -3.285em; left: 50%; margin-left: -2.23em;"><span class="mrow" id="MathJax-Span-260"><span class="mi" id="MathJax-Span-261" style="font-family: MathJax_Math-italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mi" id="MathJax-Span-262" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mo" id="MathJax-Span-263" style="font-family: MathJax_Main; padding-left: 0.251em;">+</span><span class="mi" id="MathJax-Span-264" style="font-family: MathJax_Math-italic; padding-left: 0.251em;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.127em;"></span></span><span class="mi" id="MathJax-Span-265" style="font-family: MathJax_Math-italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.065em;"></span></span></span><span style="display: inline-block; width: 0px; height: 3.973em;"></span></span><span style="position: absolute; clip: rect(0.81em 1004.53em 1.244em -999.997em); top: -1.3em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.532em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.058em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.174em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.304em; border-left: 0px solid; width: 0px; height: 3.235em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>p</mi><mo>∗</mo></msup><mo>=</mo><mfrac><mrow><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mi>C</mi><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mo>−</mo><mi>C</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-21">p^*=\frac{C(1,0)}{C(1,0)-C(0,1)}=\frac{FP}{FP+FN}</script></p>
<p>Another possibility is to "rebalance" the original training examples the ratio of:<br>
p(1)FN : p(0)FP</p>
<p>where p(1) and p(0) are the prior probability of the positive and negative examples in the original training set.</p>
<p>In summary, two main general approaches have been proposed to deal with cost-sensitive problems:</p>
<ol><li>Direct methods: The main idea of building a direct cost-sensitive learning algorithm is to directly introduce and utilize misclassification costs into the learning algorithms. For example, in the context of decision tree induction, the tree-building strategies are adapted to minimize the misclassification costs.&nbsp;</li>
<li>Meta-learning: This methodology implies the integration of a "preprocessing" mechanism for the training data or a "postprocessing" of the output, in such a way that the original learning algorithm is not modified. Cost-sensitive meta-learning can be further classified into two main categories: thresholding and sampling, which are based on the two last expressions presented respectively.</li>
</ol><h3 class="rtejustify"><a id="imb_approach" name="imb_approach">Analysis of preprocessing approaches for&nbsp;imbalanced&nbsp;big data classification</a></h3>
<p class="rtejustify">In this part of the website, we first&nbsp;present a study on preprocessing for Big Data in imbalanced classification, associated with the following paper:</p>
<ul><li class="rtejustify"><strong><a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. <em>On the use of MapReduce for Imbalanced Big Data using Random Forest. </em>Information Sciences 285 (2014) 112-137. doi: <a href="http://dx.doi.org/10.1016/j.ins.2014.03.043">10.1016/j.ins.2014.03.043</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1742_2014-delRio-INS.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></li>
</ul><p class="rtejustify">We have adapted several techniques to deal with&nbsp;imbalanced&nbsp;big data following a&nbsp;MapReduce&nbsp;scheme. Concretely, we have developed data sampling techniques such as random oversampling, random undersampling, the "Synthetic Minority Oversampling TEchnique" (SMOTE) algorithm and cost-sensitive learning. For each one of them, we will present an approach based on the&nbsp;MapReduce&nbsp;framework. In what follows, we briefly present the models that have been developed. Additionally, we will include a short analysis and the associated code with each method.</p>
<ul><li><strong>RF-BigDataCS: A cost-sensitive approach for Random Forest to deal with Imbalanced Big Data using MapReduce</strong></li>
</ul><p class="rtejustify">Inspired by the Mahout Random Forest Partial implementation we build a new Random Forest version that can be used to classify imbalanced big data. The Mahout Partial implementation (RF-BigData) is an algorithm that builds multiple trees for different portions of the data. This algorithm is divided into two different phases: the first phase is devoted to the creation of the model and the second phase is dedicated to the estimation of the classes associated with the dataset using the previous learned model. In the first phase, the Random Forest is built from the original training set following a MapReduce procedure. This process is illustrated in Figure 4 and consists of three steps: Initial, Map and Final. When the building of the forest is finished, the classification phase is initiated to estimate the class associated to a data sample set. This process is illustrated in Figure 5 and consists of three steps: Initial, Map and Final.</p>
<p class="rtejustify">To adapt the cost-sensitive learning based version of Random Forest to the Mahout environment, we need to include the cost-sensitive operations into the basic Random Forest implementation.</p>
<p class="rtecenter">&nbsp;</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/rf_cs_big.png" style="width: 598px; height: 437px;"></p>
<p class="rtecenter">Figure 4: A flowchart of how the building of the Random Forest is organized in the RF-BigDataCS algorithm.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/rf_cs_bigclas.png" style="width: 507px; height: 319px;"></p>
<p class="rtecenter">Figure 5: A flowchart of how the classifying step is organized in the RF-BigDataCS algorithm.</p>
<p>The source code is available in GitHub.</p>
<p><a href="https://github.com/saradelrio/RF-BigDataCS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/RF-BigDataCS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/rf_mr.png" style="width: 291px; height: 68px;"></a></p>
<ul><li><strong>Random oversampling for big data: An approximation with MapReduce</strong></li>
</ul><p class="rtejustify">The Random Oversampling (ROS) algorithm has been adapted to deal with big data following a MapReduce design where each Map process is responsible for adjusting the class distribution in a mapper’s partition through the random replication of minority class instances and the Reduce process is responsible for collecting the outputs generated by each mapper to form the balanced dataset. This process is illustrated in Figure 6 and consists of four steps: Initial, Map, Reduce and Final.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/ros.png" style="width: 576px; height: 283px;"></p>
<p class="rtecenter">Figure 6: A flowchart of how the ROS MapReduce design works.</p>
<p>The source code is available in GitHub.</p>
<p><a href="https://github.com/saradelrio/hadoop-imbalanced-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/hadoop-imbalanced-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/hadoop.png" style="width: 492px; height: 68px;"></a></p>
<ul><li><strong>Random undersampling for big data: Selecting samples following a MapReduce procedure</strong></li>
</ul><p class="rtejustify">The Random Undersampling (RUS) version adapted to deal with big data follows a MapReduce design where each Map process is responsible for grouping by classes all the instances in its data partition and the Reduce process is responsible for collecting the output by each mapper and equilibrating the class distribution through the random elimination of majority class instances to form the balanced dataset. This process is illustrated in Figure 7 and consists of four steps: Initial, Map, Reduce and Final.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/rus.png" style="width: 568px; height: 327px;"></p>
<p class="rtecenter">Figure 7: A flowchart of how the RUS MapReduce design works.</p>
<p>The source code is available in GitHub.</p>
<p><a href="https://github.com/saradelrio/hadoop-imbalanced-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/hadoop-imbalanced-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/hadoop.png" style="width: 492px; height: 68px;"></a></p>
<ul><li><strong>SMOTE for big data: Adapting the generation of synthetic minority samples using MapReduce</strong></li>
</ul><p class="rtejustify">The SMOTE algorithm has been adapted to deal with big data following a MapReduce design where each Map process oversamples the minority class and the Reduce process randomizes the output generated by each mapper to form the balanced dataset. This process is illustrated in Figure 8 and consists of four steps: Initial, Map, Reduce and Final.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/smote(1).png" style="width: 599px; height: 293px;"></p>
<p class="rtecenter">Figure 8: A flowchart of how the SMOTE MapReduce design works.</p>
<p>The source code is available in GitHub.</p>
<p><a href="https://github.com/saradelrio/hadoop-imbalanced-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/hadoop-imbalanced-preprocessing"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/hadoop.png" style="width: 492px; height: 68px;"></a></p>
<p>Finally, we include several experimental results for the former studies. These can be accessed by clicking on each excel logo.</p>
<ul><li>Average results for the MapReduce RF versions using 8, 16, 32 and 64 mappers on the imbalanced big data cases based on the kddcup dataset&nbsp;<a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/detailed_average_gm_results_kddcup.xlsx"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/excel_icon.gif" style="width: 30px; height: 30px;"></a></li>
<li>Average results for the MapReduce RF versions using 8, 16, 32 and 64 mappers on the RLCP dataset&nbsp;<a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/detailed_average_gm_results_rlcp.xlsx"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/excel_icon.gif" style="width: 30px; height: 30px;"></a></li>
<li>Average results for the MapReduce RF versions using 8, 16, 32 and 64 mappers on the imbalanced big data cases based on the poker dataset&nbsp;<a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/detailed_average_gm_results_poker.xlsx"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/excel_icon.gif" style="width: 30px; height: 30px;"></a></li>
</ul><p>&nbsp;</p>
<h3><a id="oversampling" name="oversampling">Analysis of the oversampling rate for extremely imbalanced big data</a></h3>
<p class="rtejustify">In imbalanced classification problems the lack of density of the minority class causes a negative impact in the performance. In big data, the impact is further increased when the original data are partitioned into subsets by the MapReduce procedure.</p>
<p class="rtejustify">For this reason, we analyze a hypothesis to deal with extremely imbalanced big data problems increasing the presence of the underrepresented class. Our hypothesis stated that an increment in the density of the underrepresented class by using higher oversampling ratios could improve the classification performance.</p>
<p class="rtejustify">In order to evaluate the performance of our solution, we used the extremely imbalanced big data problem used in the ECBDL’14 Big Data Competition with nearly 32 million examples and 631 features. We use the MapReduce versions of the random oversampling (ROS) and the random undersampling (RUS) techniques (<em><a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. On the use of MapReduce for Imbalanced Big Data using Random Forest. Information Sciences 285 (2014) 112-137</em>) in order to balance the highly imbalanced class distribution of the dataset. Furthermore, due to the large number of features that this dataset has, we also apply the MapReduce approach for evolutionary feature weighting (<em>I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, J. Bacardit,&nbsp;<a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.&nbsp;ROSEFW-RF: The winner algorithm for the ECBDL'14 Big Data Competition: An extremely imbalanced big data bioinformatics problem.&nbsp;Knowledge-Based Systems 87 (2015) 69-79</em>) with the aim of detect the most significant features. We use as base classifier a MapReduce implementation of the Random Forest algorithm (RF-BigData).</p>
<p class="rtejustify">In order to bias the RF-BigData classifier towards the minority class, we consider to increase the density of this class. We increment the oversampling ratio in small steps from 105% to 180%. The following figure shows the procedure that we have carried out:</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/flowchart-process-to-increase_TPR.png" style="width: 300px; height: 331px;"></p>
<p class="rtecenter">Flowchart illustrating the process to increase the True Positive Rate</p>
<p>The experiments carried out over the ECBDL’14 Big Data Competition dataset support this hypothesis and have yielded an improvement in the overall accuracy. Setting the oversampling ratio to a value that balances the True Positive Rate and the True Negative Rate values leads to the best performance in terms of accuracy.</p>
<p>This work has been published in the following reference:</p>
<ul><li><strong><a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. "Analysis of Data Preprocessing Increasing the Oversampling Ratio for Extremely Imbalanced Big Data Classification", The 9th IEEE International Conference on Big Data Science and Engineering (IEEE BigDataSE-15), Volume 2; Helsinki (Finland), 180-185, August 20-22, 2015, doi: <a href="http://dx.doi.org/10.1109/Trustcom.2015.579">10.1109/Trustcom.2015.579</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1952_PID3782547.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></li>
</ul><p>&nbsp;</p>
<h3><a id="eus" name="eus">Evolutionary&nbsp;Undersampling&nbsp;for&nbsp;Imbalanced&nbsp;Big Data Classification</a></h3>
<p>We have developed a parallel model to enable evolutionary undersampling methods to deal with large-scale problems. To do this, we design a MapReduce scheme that distributes the operation of these kinds of algorithms in a cluster of computing elements.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/Flowchart_EUS.png" style="width: 500px; height: 363px;"></p>
<p class="rtecenter">Flowchart of the learning phase of EUS-based decision tree classifier ensemble.</p>
<p>Moreover, we develop &nbsp;a windowing approach for class imbalance data without losing accuracy in order to speed up the undersampling process. The results show promising scalability abilities for evolutionary undersampling within the proposed framework.</p>
<p>The source code is available on GitHub:</p>
<p><a href="https://github.com/triguero/EUS-BigData"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width:94px;height:50px;"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/EUS-BigData.png" style="height: 60px; width: 264px;"></a></p>
<p><strong>I. Triguero, M. Galar, S. Vluymans, <a href="http://sci2s.ugr.es/members#CCornelis">C. Cornelis</a>, H. Bustince, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, Y. Saeys.</strong> <em>Evolutionary Undersampling for Imbalanced Big Data Classification.</em> IEEE Congress on Evolutionary Computation (CEC 2015), Sendai (Japan), 715-722, May 25-28, 2015. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1930_097-15239.pdf" title=" (824.8K)"><img alt="PDF Icon" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></p>
<h2 class="rtejustify">&nbsp;</h2>
<h2 class="rtejustify"><a id="Big-Data-Fuzzy" name="Big-Data-Fuzzy"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/bigdata_02_2.png" style="width: 175px; height: 80px; float: left;">Big Data classification with fuzzy models</a></h2>
<p class="rteindent4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. <a href="http://sci2s.ugr.es/BigData#intro_frbcs">Introduction to FRBCS</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. <a href="http://sci2s.ugr.es/BigData#chi_big">The Chi-FRBCS-BigData algorithm: A MapReduce Design based on the Fusion of Fuzzy Rules</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. <a href="http://sci2s.ugr.es/BigData#chi_imb">The Chi-FRBCS-BigDataCS algorithm for imbalanced bigdata with cost sensitive: A MapReduce design</a></p>
<p class="rteindent4">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4.&nbsp;<a href="http://sci2s.ugr.es/BigData#fuzzy-gran">Fuzzy Rule Based Classification Systems for Big Data with MapReduce: Granularity Analysis</a></p>
<p class="rteindent4">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 5.&nbsp;<a href="http://sci2s.ugr.es/BigData#fuzzy-review">A View on Fuzzy Systems for Big Data: Progress and Opportunities</a></p>
<p class="rteindent4">&nbsp;</p>
<h3 class="rtejustify"><a id="intro_frbcs" name="intro_frbcs">Introduction to FRBCS</a></h3>
<p class="rtejustify"><strong>Fuzzy Rule Based Classification Systems (FRBCSs)</strong> (<em>H. Ishibuchi, T. Nakashima, M. Nii, Classification and Modeling with Linguistic Information Granules: Advanced Approaches to Linguistic Data Mining, Springer-Verlag, 2004</em>) are effective and accepted tools for pattern recognition and classification. They are able to obtain a good precision while supplying an interpretable model for the end user through the usage of linguistic labels. Furthermore, the FRBCSs can manage uncertainty, ambiguity or vagueness in a very effective way. This trait is especially interesting when dealing with big data, as uncertainty is inherent to this situation. However, when dealing with big data, the information at disposal usually contains a high number of instances and/or features. In this scenario the inductive learning capacity of FRBCSs is affected by the exponential growth of the search space. This growth complicates the learning process and it can lead to scalability problems or complexity problems generating a rule set that is not interpretable (<em>Y. Jin, Fuzzy modeling of high-dimensional systems: complexity reduction and interpretability improvement, IEEE Trans. Fuzzy Syst. 8 (2) (2000) 212-221</em>).</p>
<p class="rtejustify">To over come this situation there have been several approaches that aim to build parallel fuzzy systems (<em>T.-P. Hong, Y.-C. Lee, M.-T. Wu, An effective parallel approach for genetic-fuzzy data mining, Expert Syst. Appl. 41 (2) (2014) 655-662</em>). These approaches can distribute the creation of the rule base (<em>M. Rodríguez, D. Escalante, A. Peregrín, Efficient distributed genetic algorithm for rule extraction, Appl. Soft Comput. 11 (1) (2011) 733-743</em>) or the post-processing of the built model, using a parallelization to perform a rule selection (<em>Y. Nojima, H. Ishibuchi, I. Kuwajima, Parallel distributed genetic fuzzy rule selection, Soft Comput. 13 (5) (2009) 511-519</em>) or a lateral tuning of the fuzzy labels <em>(I. Robles, <a href="http://sci2s.ugr.es/members#RAlcala">R. Alcalá</a>, J. Benítez, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, Evolutionary parallel and gradually distributed lateral tuning of fuzzy rule-based systems, Evol. Intel. 2 (1–2) (2009) 5-19</em>). Moreover, a fuzzy learning model can be completely redesigned to obtain a parallel approach that decreases the computation time needed (<em>H. Ishibuchi, S. Mihara, Y. Nojima, Parallel distributed hybrid fuzzy GBML models with rule set migration and training data rotation, IEEE Trans. Fuzzy Syst. 21(2) (2013) 355-368</em>). However, these models aim to reduce the wait for a final classification without damaging the performance and are not designed to handle huge volumes of data. In this manner, it is necessary to redesign the FRBCSs accordingly to be able to provide an accurate classification in a small lapse of time from big data.</p>
<h3 class="rtejustify"><a id="chi_big" name="chi_big">The Chi-FRBCS-BigData algorithm: A MapReduce Design based on the Fusion of Fuzzy Rules</a></h3>
<p class="rtejustify">We have developed an FRBCS that can deal with big data classification problems providing an interpretable model and competitive accuracy results. Our implementation, denoted as Chi-FRBCS-BigData, is based on the Chi et al.'s approach (<em>Z. Chi, H. Yan and T. Pham, Fuzzy algorithms with applications to image processing and pattern recognition, World Scientific, (1996)</em>), a classical FRBCS learning method which has been adapted to deal with big data following a MapReduce scheme.</p>
<p class="rtejustify">The fusion of linguistic fuzzy rules is a fundamental task in the approach due to the nature of the MapReduce procedure, which divides the original dataset into blocks. The Chi-FRBCS-BigData algorithm can generate contradictory rules (rules with the same antecedent, with or without the same consequent and with different rule weights), so it is necessary to address how the fusion of rules is performed with specific procedures. To do this, two different versions of Chi-FRBCS-BigData approach have been developed:<strong> Chi-FRBCS-BigData-Max</strong> and <strong>Chi-FRBCS-BigData-Ave</strong>. While both versions share most of their operations, they differ in the reduce step of the approach, where the generated rule bases are combined. Therefore, these variants of Chi-FRBCS-BigData algorithm obtain different final rule bases.</p>
<p class="rtejustify">The Chi-FRBCSBigData algorithm uses two different MapReduce processes. One MapReduce process is devoted to the building of the model from a big data training set (Figure 9). The other MapReduce process is used to estimate the class of the examples belonging to big data sample sets using the previous learned model (Figure 10). Both parts follow the MapReduce design, distributing all the computations along several processing units that manage different chunks of information, aggregating the results obtained in an appropriate manner. The two versions developed, which we have named Chi-FRBCS-BigData-Max and Chi-FRBCSBigData-Ave share most of their operations, however, they behave differently in the reduce step of the approach, when the different RBs generated by each map are fused. These versions obtain different RBs and thus, different KBs.</p>
<p>&nbsp;</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/chi_frbcs_bigdata_build.png" style="width: 841px; height: 179px;"></p>
<p class="rtecenter">Figure 9: A flowchart of how the building of the KB is organized in Chi-FRBCS-BigData</p>
<p>&nbsp;</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/chi_frbcs_bigdata_clas.png" style="width: 575px; height: 207px;"></p>
<p class="rtecenter">Figure 10: flowchart of how the classification of a big dataset is organized in Chi-FRBCS-BigData</p>
<p>The source codes for both&nbsp;Chi-FRBCS-BigData-Max and Chi-FRBCS-BigData-Ave are&nbsp;available in GitHub.</p>
<p><a href="https://github.com/saradelrio/Chi-FRBCS-BigData-Max"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/Chi-FRBCS-BigData-Max"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/chi_max.png" style="width: 392px; height: 68px;"></a></p>
<p><a href="https://github.com/saradelrio/Chi-FRBCS-BigData-Ave"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/Chi-FRBCS-BigData-Ave"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/chi_ave.png" style="width: 385px; height: 68px;"></a></p>
<p><strong><a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>. </strong><em>A MapReduce Approach to Address Big Data Classification Problems Based on the Fusion of Linguistic Fuzzy Rules. </em>International Journal of Computational Intelligence Systems 8:3 (2015) 422-437. doi: <a href="http://dx.doi.org/10.1080/18756891.2015.1017377">10.1080/18756891.2015.1017377</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1860_delRio-lopez-benitez-herrera-Chi-FRBCS-MapReduce.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></p>
<h3 class="rtejustify"><a id="chi_imb" name="chi_imb">The Chi-FRBCS algorithm for imbalanced bigdata: A MapReduce design</a></h3>
<p>We have implemented a FRBCS that is capable of classifying&nbsp;imbalanced&nbsp;big data which has been denoted as Chi-FRBCS-BigDataCS. The method is based on the Chi et al.’s approach (Z. Chi, H. Yan, T. Pham, Fuzzy Algorithms with Applications to Image Processing and Pattern Recognition, World Scientific,1996), a classical FRBCS learning method, which has been modified to deal with&nbsp;imbalanced&nbsp;datasets and big data at the same time.</p>
<p class="rtejustify">Specifically, the Chi-FRBCS-BigDataCS algorithm is a MapReduce design where each map process is responsible for building a Rule Base using only the data included in its portion and where the reduce process is responsible for collecting and combining the Rule Base generated by each mapper to form the final Rule Base.<strong> </strong>This algorithm is divided into two different phases: the first phase is devoted to the creation of the model, Figure 11, and the second part is devoted to the estimation the class associated to a dataset. Both phases follow the MapReduce structure distributing all the computations needed along several processing units that manage different chunks of information, aggregating the results obtained in an appropriate manner.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/building_chi_job.png" style="width: 731px; height: 403px;"></p>
<p class="rtecenter">Figure 11: A flowchart of how the building of the KB is organized in Chi-FRBCS-BigDataCS.</p>
<p>The source code is available in GitHub.</p>
<p><a href="https://github.com/saradelrio/Chi-FRBCS-BigDataCS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a>&nbsp;<a href="https://github.com/saradelrio/Chi-FRBCS-BigDataCS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/chi_cs.png" style="width: 371px; height: 68px;"></a></p>
<p><strong>V. López, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>. <em>Cost-Sensitive Linguistic Fuzzy Rule Based Classification Systems under the MapReduce Framework for Imbalanced Big Data</em>. Fuzzy Sets and Systems 258 (2015) 5-38.&nbsp;<a href="http://dx.doi.org/10.1016/j.fss.2014.01.015">http://dx.doi.org/10.1016/j.fss.2014.01.015</a> <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1734_2015-lopez-FSS.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<h3><a id="fuzzy-gran" name="fuzzy-gran">Fuzzy Rule Based Classification Systems for Big Data with MapReduce: Granularity Analysis</a></h3>
<p>It is well known that the number of fuzzy&nbsp;labels for building the DB is a significant parameter to achieve a precise description of the problem space, i.e.&nbsp;can be viewed as a sort of context information. Therefore, depending on the problem structure and the data scattering, a higher or lower number of linguistic terms will be needed in order to provide a good discrimination ability.&nbsp;Particularly, if the classes are highly overlapping, the level of granularity to allow a good discrimination of the examples gets higher. Therefore, the data distribution is one of the main characteristics to determine the most appropriate value of the granularity, as it has a&nbsp;significant influence on the FRBCS performance.</p>
<p>When we obtain the KB within a MapReduce approach, we must be aware that the number of maps selected for this process imply a&nbsp;very different distribution of the data. Hence, as more efficiency is demanded, so it does the scattering of the original data among the map functions.</p>
<p>Regarding this fact, we can assume that the differences in performance for any classification problem regarding the number of&nbsp;Maps selected, will become less significant as the number of labels increases. This is due to several facts. On the one hand, the&nbsp;capabilities of fuzzy learning algorithms make them less sensible to the "lack of data."&nbsp;On the other hand, a higher&nbsp;granularity allows the construction of a robust model, in accordance to the more detailed representation of the space of the&nbsp;problem.</p>
<p>In this context, we carry out the following research:</p>
<ol><li>First, to&nbsp;study&nbsp;the dependency of the granularity level, i.e. number of fuzzy labels per variable, and the number of selected Maps for the FRBCS in Big Data problems. In order to do so, we have selected the Chi-FRBCS-BigData algorithm in an experimental framework with datasets of different characteristics (especially in terms of number of examples).</li>
<li>Additionally, our experimental results determine the benefit of a higher granularity in this context for all case studies. This is due to the use of better local representation of the generated subproblems in addition to the final fusion of rules.</li>
<li>Finally, we show that FRBCSs are robust in terms of the data scattering, maintaining a good performance even when increasing the number of Maps used. In this way, this type of systems has the advantage of their scalability.</li>
</ol><p><strong>A. Fernandez,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>.&nbsp;<em>Fuzzy Rule Based Classification Systems for Big Data with MapReduce: Granularity Analysis</em>.&nbsp;Advances in Data Analysis and Classification,&nbsp;in press.&nbsp;doi: <a href="http://dx.doi.org/10.1007/s11634-016-0260-z">10.1007/s11634-016-0260-z</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/2086_2016-ADAC-FuzzyGranularityBigData.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<p><a id="fuzzy-review" name="fuzzy-review">A View on Fuzzy Systems for Big Data: Progress and Opportunities</a></p>
<p>It is well known that a fuzzy&nbsp;representation for the modeling of solutions, allows a simplicity and flexibility which makes them&nbsp;suitable for addressing complex problems. This can be achieved as they are able to cope with vague, imprecise or uncertain&nbsp;concepts that human beings use in their usual reasoning, as well as their interpretability based on the linguistic&nbsp;variables.</p>
<p>In the context of Big Data problems, the former properties make them a valuable tool for developing robust solutions, handling&nbsp;the variety and veracity inherent to the available data. Additionally, the use of fuzzy labels and their overlapping, allows a&nbsp;good coverage of the problem space. This last fact is especially significant for the MapReduce processing scheme. Specifically,&nbsp;we are referring to the case when the division of the original data into different chunks may cause a bias for the presence of&nbsp;small disjuncts, i.e. those disjuncts in the learned classifier that cover few training examples.</p>
<p>Taking the former into account, we provided an analysis of fuzzy modeling for different tasks in Big Data problems, i.e. classification, clustering, subgroup discovery, and so on. Being a novel area of research, there were still few works on the topic. Therefore, we considered to be of high&nbsp;importance&nbsp;to understand the nature of Big Data and how this problem is currently addressed. In this sense, some criteria for the correct development of solutions under the umbrella of fuzzy sets must be established. This way, we can achieve the highest advantage in extending current approaches. In summary, we aimed at defining the direction for the design of powerful algorithms based on fuzzy systems, and how the information extracted with these models can be useful for the experts.</p>
<p>Particularly, we presented the current features related to fuzzy approaches in the scenario of Big Data into three different blocks:&nbsp;</p>
<ol><li><strong>What has been done</strong>.&nbsp;First, we presented those methodologies that have been already developed in this area of research.</li>
<li><strong>How it can be designed</strong>.&nbsp;Next, we introduced several guidelines for the implementation of fuzzy models into a MapReduce framework.</li>
<li><strong>Associated problems of the MapReduce paradigm for classification</strong>.&nbsp;Finally, we&nbsp;pointed out some problems associated to the MapReduce execution style, and how the properties of fuzzy systems make them well suited to overcome them.</li>
</ol><p>To conclude our study, we carried out a discussion for fuzzy modeling in a Big Data scenario. Specifically, we considered that new research in the Big Data scenario for fuzzy modeling must be focused on re-designing the state-of-the-art algorithms, as well as novel approaches for recent work scenarios. By doing so, a complete library of methods would be available for researchers and experts to take the full advantage of this novel work area. Additionally, this can be used as basis for the development of novel and more powerful fuzzy algorithms. However, the transition from standard learning approaches towards the MapReduce parallel model is not straightforward, and requires a thorough analysis of the designer.</p>
<p>In order to do so, we must focus our attention on a careful definition of the mechanisms of information combination. In this sense, the "Reduce"&nbsp;phase must be analyzed in detail. We must take into account the handicap of the division in the computation for different Maps, and to study the dependency of the models that have been learned in each one of the former. Determining an optimal combination of these models is a fundamental decision when applying a MapReduce scheme in Big Data Analytics. A smart combination of the systems learned within each Map must be carried out seeking for a good synergy, thus avoiding the local bias from the subsets they were learned with.</p>
<p>Finally, there are plenty of new and complex paradigms that are growing in importance in the last years that must be also taken into account. We may refer to multi-instance learning, multi-label, monotonic classification, semi-supervised learning, multi-view learning, social mining, and opinion mining, to enumerate the most relevant ones. Another source of research is the management of data streams, where the time constraints and the need for an adaptive learning approach, imply a higher degree of difficulty.</p>
<p><strong>A. Fernandez, C.J. Carmona, M.J. del Jesus,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a></strong>.&nbsp;<em>A View on Fuzzy Systems for Big Data: Progress and Opportunities</em>.&nbsp;International Journal of Computational Intelligence Systems, 9:1 (2016), 69-80 doi:&nbsp;<a href="http://dx.doi.org/10.1080/18756891.2016.1180820">10.1080/18756891.2016.1180820</a>. <a href="http://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/2082_ijcis3726.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<h2><a id="kNN" name="kNN">Classification Algorithms: k-NN</a></h2>
<p>The k-Nearest Neighbor classifier is one of the most well-known methods in data mining because of its effectiveness and simplicity. However, It lacks the scalability to manage big datasets. The main problems found for dealing with large-scale data are runtime and memory consumption.</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/Flowchart_kNN.png" style="width: 600px; height: 458px;"></p>
<p class="rtecenter">Flowchart of the proposed MR-kNN algorithm.&nbsp;</p>
<p>The source code is available on GitHub.<br><a href="https://github.com/JMailloH/KNN"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a><a href="https://github.com/JMailloH/KNN"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/MR-kNN.png" style="width: 223px; height: 65px;"></a></p>
<p>The two approaches are developed under MapReduce paradigm. MR-kNN is our approach developed in Apache Hadoop. This model allows us to classify large amounts of test examples against a big training dataset. The map phase computes the k-nearest neighbors in different splits of the training data. Afterward, the reduce stage will compute the definitive neighbors from the list obtained in the map phase. Moreover, this parallel implementation provides the exact classification rate as the original k-NN model. The experiments show the promising scalability capabilities of the proposed approach.</p>
<p><strong>J. Maillo, I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong>&nbsp;<em>A MapReduce-based k-Nearest Neighbor Approach for Big Data Classification.</em>&nbsp;9th International Conference on Big Data Science and Engineering (IEEE BigDataSE-15), Volume 2; Helsinki (Finland), 167-172, August 20-22, 2015. <a href="http://dx.doi.org/10.1109/Trustcom.2015.577">doi: 10.1109/Trustcom.2015.577 </a><a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/A%20MapReduce-based%20k-Nearest%20Neighbor%20Approach%20for%20Big%20Data%20Classification-IEEE%20BigDataSE-2015.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<p>Motivated with the results of MR-kNN, we design and develop another proposal. This is implemented in Apache Spark, using their primitive instructions in order to work with main memory and do even more scalable by iterating over the test set , if it is needed.</p>
<p class="rtecenter"><img alt="" height="878" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/kNN_IS_flowchart.png" width="878"></p>
<p class="rtecenter">Flowchart of the proposed kNN-IS algorithm.&nbsp;</p>
<p>This flowchart shows the iterative process of our Iterative approach. For each iteration, the map phase computes the k nearest neighbors of a split of the test set against the complete training set. The reduce phase combines the candidates neighbors and It selects the final k nearest neighbors of these.</p>
<p>The source code is available on GitHub.<br><a href="https://github.com/JMailloH/kNN_IS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.png" style="width: 94px; height: 50px;"></a><a href="https://github.com/JMailloH/kNN_IS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/kNN-IS.png" style="width: 263px; height: 57px;"></a><br>
Also, It is available as a software on Spark package.<br><a href="https://spark-packages.org/package/JMailloH/kNN_IS"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/spark-package.png" style="width: 191px; height: 55px;"></a></p>
<p>kNN-IS is more efficient than MR-kNN and It is available in spark-package and GitHub with two different data structure. The MLlib version runs over RDD structures. The ML version runs over DataFrame.</p>
<p><strong>J. Maillo, <a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a>, I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.</strong>&nbsp;<em>kNN-IS: An Iterative Spark-based design of the k-Nearest Neighbors classifier for big data.</em>&nbsp;Knowledge-Based Systems, in press <a href="http://dx.doi.org/10.1016/j.knosys.2016.06.012">doi: 10.1016/j.knosys.2016.06.012 </a><a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/kNN_IS.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<p>&nbsp;</p>
<h2><a name="Applications" id="Applications"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/bigdataapps2.png" style="width: 175px; height: 117px; float: left;">Big Data Applications</a></h2>
<p class="rteindent1">&nbsp; &nbsp;In this section we present the list of large-scale problems tackled by our distributed algorithms. Likewise, the associated works to these problems are listed below:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.&nbsp;<a href="http://sci2s.ugr.es/BigData#ContactMap">Contact Map Prediction (Protein structure prediction)</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.&nbsp;<a href="http://sci2s.ugr.es/BigData#Ortholog">Ortholog&nbsp;Detection in Related Yeast Species</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<h3><a id="ContactMap" name="ContactMap"><strong>Contact Map Prediction (Protein structure prediction)</strong></a></h3>
<p>Contact Map (CM) prediction is a bioinformatics (and specifically a protein structure prediction) classification task that is an ideal test case for a big data challenge for several reasons. CM data sets easily reach tens of millions of instances, hundreds (if not thousands) of attributes and<br>
have an extremely high class imbalance.&nbsp; In this work we describe step-by-step the methodology with which we have participated, under the name ’Efdamis’, in the ECBDL’14 competition (described in the Dataset Repository Section), ranking as the winner algorithm. Figure 12 summarizes the procedure we followed in the competition:</p>
<p class="rtecenter"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/flowchart" style="width: 731px; height: 403px;"><br>
&nbsp;</p>
<p class="rtecenter">Figure 12: Flowchart of the procedure followed during the competition.</p>
<p class="rtejustify">This work has been published in the following reference:</p>
<p><strong>I. Triguero,&nbsp;<a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, J. Bacardit,&nbsp;<a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>,&nbsp;<a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.&nbsp;</strong><em>ROSEFW-RF: The winner algorithm for the ECBDL'14 Big Data Competition: An extremely imbalanced big data bioinformatics problem.</em>&nbsp;Knowledge-Based Systems 87 (2015) 69-79.&nbsp;doi: <a href="http://www.sciencedirect.com/science/article/pii/S0950705115002130">10.1016/j.knosys.2015.05.027</a>&nbsp; <a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-Knosys-triguero_rosefw-RF.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png" style="width: 24px; height: 24px;"></a></p>
<p class="rtejustify">&nbsp;</p>
<h3><a id="Ortholog" name="Ortholog"><strong>Ortholog Detection in Related Yeast Species</strong></a></h3>
<p>In this paper, a set of gene pair features based on similarity measures, such as alignment scores, sequence length, gene membership to conserved regions, and physicochemical profiles, are combined in a supervised pairwise ortholog detection (POD) approach to improve effectiveness considering low ortholog ratios in relation to the possible pairwise comparison between two genomes. In this POD scenario, big data supervised classifiers managing imbalance between ortholog and non-ortholog pair classes allow for an effective scaling solution built from two genomes and extended to other genome pairs.</p>
<p>This work has been published in the following reference:</p>
<p><strong>D. Galpert, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, E. Ancede-Gallardo, A. Antunes, G. Agüero-Chapin.</strong> <em>An Effective Big Data Supervised Imbalanced Classification Approach for Ortholog Detection in Related Yeast Species</em>. BioMed Research International, vol. 2015, Article ID 748681, 12 pages, 2015. doi: <a href="http://www.hindawi.com/journals/bmri/2015/748681/">10.1155/2015/748681&nbsp;</a><a href="http://downloads.hindawi.com/journals/bmri/aip/748681.pdf"> </a> <a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/2015-hindawi-dgalpert.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/pdf_download.png"></a></p>
<p>&nbsp;</p>
<h2><a name="Datasets" id="Datasets"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/bigdata_03_2.png" style="width: 175px; height: 117px; float: left;">Dataset repository</a></h2>
<p>&nbsp;In this section we provide a collection of different datasets and problems that can be used for classification tasks with Big Data. Currently, it is divided into four different parts: (1) datasets taken for the well-known UCI Machine Learning Repository; (2) datasets selected from the LibSVM repository; (3) a link to Pascal large scale repository; and (4) individual&nbsp; problems.</p>
<ul><li class="rtejustify"><strong>UCI Machine Learning Repository</strong>: <a href="https://archive.ics.uci.edu/ml/datasets.html">https://archive.ics.uci.edu/ml/datasets.html</a>
<ul><li class="rtejustify"><strong>HIGGS</strong>: This is a classification problem to distinguish between a signal process which produces Higgs bosons and a background process which does not. The dataset has 11,000,000 instances, 28 attributes and 2 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/HIGGS">https://archive.ics.uci.edu/ml/datasets/HIGGS</a></li>
<li class="rtejustify"><strong>Record Linkage Comparison Patterns: Source</strong>:&nbsp;Element-wise comparison of records with personal data from a record linkage setting. The task is to decide from a comparison pattern whether the underlying records belong to one person.&nbsp;The dataset has 5,749,132 instances, 12 attributes and 2 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/Record+Linkage+Comparison+Patterns">https://archive.ics.uci.edu/ml/datasets/Record+Linkage+Comparison+Patterns</a></li>
<li class="rtejustify"><strong>SUSY</strong>: This is a classification problem to distinguish between a signal process which produces supersymmetric particles and a background process which does not. The dataset has 5,000,000 instances, 18 attributes and 2 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/SUSY">https://archive.ics.uci.edu/ml/datasets/SUSY</a></li>
<li class="rtejustify"><strong>KDD Cup 1999</strong>: This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between "bad" connections, called intrusions or attacks, and "good" normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment. The dataset has 4,000,000 instances, 42 attributes and 22 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data">https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data</a></li>
<li class="rtejustify"><strong>Poker Hand</strong>: Purpose is to predict poker hands.&nbsp;The dataset has 1,025,010 instances, 10 attributes and 10 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand">https://archive.ics.uci.edu/ml/datasets/Poker+Hand</a></li>
<li class="rtejustify"><strong>Covertype</strong>: Forest CoverType dataset. The dataset has&nbsp;581,012 instances, 54 attributes and 7 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/Covertype">https://archive.ics.uci.edu/ml/datasets/Covertype</a></li>
<li class="rtejustify"><strong>Census</strong>: This data set contains weighted census data extracted from the 1994 and 1995 current population surveys conducted by the U.S. Census Bureau.&nbsp;The dataset has&nbsp;299,285 instances, 40 attributes and 2 classes. Source: <a href="https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29">https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29</a></li>
</ul></li>
<li class="rtejustify"><strong>LIBSVM Dataset Repository</strong>: <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/">http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/</a>
<ul><li class="rtejustify"><em><strong>epsilon</strong></em>: The raw data set (epsilon_train) is instance-wisely scaled to unit length and split into two parts: 4/5 for training and 1/5 for testing. The training part is feature-wisely normalizied to mean zero and variance one and then instance-wisely scaled to unit length. Using the scaling factors of the training part, the testing part is processed in a similar way. <span style="display: none;">&nbsp; </span>The dataset has 500,000 instances, 2000 attributes and 2 classes. Source: <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#epsilon">http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#epsilon</a></li>
</ul></li>
<li class="rtejustify"><strong>Pascal Large Scale Learning Challenge Repository</strong>: <a href="ftp://largescale.ml.tu-berlin.de/largescale/">ftp://largescale.ml.tu-berlin.de/largescale/</a></li>
<li class="rtejustify"><strong>Individual datasets</strong>:
<ul><li class="rtejustify"><strong><em>ECBDL14</em></strong>: generated to train a predictor for the residue-residue contact prediction track of the CASP9 competiton. The dataset has 32 million instances, 631 attributes, 2 classes, 98% of negative examples and occupies, when uncompressed, about 56GB of disk space. Source: <a href="http://cruncher.ncl.ac.uk/bdcomp/">http://cruncher.ncl.ac.uk/bdcomp/</a></li>
</ul></li>
</ul><p class="rtejustify">&nbsp;</p>
<h2 class="rtejustify"><a id="Reviews" name="Reviews"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/Literature-Review-HQ-logo.png" style="width: 119px; height: 110px; float: left;">Literature review: surveys and overviews</a></h2>
<script type="text/javascript" language="JavaScript">
<!--//--><![CDATA[// ><!--
<!--
function HideContent(d) {
document.getElementById(d).style.display = "none";
}
function ShowContent(d) {
document.getElementById(d).style.display = "block";
}
function ReverseDisplay(d) {
if(document.getElementById(d).style.display == "none") { document.getElementById(d).style.display = "block"; }
else { document.getElementById(d).style.display = "none"; }
}
//-->
//--><!]]>
</script><p>The field of Big Data has experienced a flourishing growth in the last decade. Many interesting works have been developed under this area; not only new approaches, but several survey papers, books and other research to address scalability in this scenario.</p>
<p class="rtejustify">With this aim, in this section some recent overviews on the topic are collected. The list is devoted to be of high interest for the research community in Big Data. Please click on the "abstract link" in order to show/hide the abstract for each paper.</p>
<h3>Surveys and overviews</h3>
<ul><li>A. Fernandez, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, V. López, A. Bawakid, M.J. del Jesus, <a href="http://sci2s.ugr.es/members#JMBenitez">J.M. Benítez</a>, <a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>.&nbsp;Big Data with Cloud Computing: An Insight on the Computing Environment, MapReduce and Programming Frameworks. WIREs Data Mining and Knowledge Discovery 4(5):&nbsp;380-409. doi:&nbsp;<a href="http://dx.doi.org/10.1002/widm.1134">10.1002/widm.1134</a>&nbsp;(2014)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper9&#39;)">Abstract:</a></strong>&nbsp;</p>
<div id="paper9" style="display:none;">The term "Big Data"&nbsp;has spread rapidly in the framework of Data Mining and Business Intelligence. This new scenario can be&nbsp;defined by means of those problems that cannot be effectively or efficiently addressed through the standard computing resources&nbsp;than we currently have. We must emphasize that Big Data does not just imply large volumes of information, but also the&nbsp;necessity for scalability, i.e. to ensure a response in an acceptable elapsed-time.&nbsp;When the scalability term is considered, usually traditional parallel-type solutions are associated, such as the Message Passing&nbsp;Interface or high performance and distributed Data Base Management Systems. Nowadays there is a new paradigm that has gained&nbsp;popularity over the latter due to the number of benefits it offers. This model is Cloud Computing, and among its main features we&nbsp;must stress its elasticity in the use of computing resources and space, less management effort, and flexible costs.&nbsp;In this paper, we provide an overview on the topic of Big Data, and how the current problem can be addressed from the perspective&nbsp;of Cloud Computing and its programming frameworks. In particular, we focus on those systems for large scale analytics based on&nbsp;the MapReduce scheme and Hadoop, its open-source implementation. We identify several libraries and software projects that have&nbsp;been developed for aiding practitioners to address this new programming model. We also analyze the advantages and disadvantages&nbsp;of MapReduce, in contrast to the classical solutions in this field. Finally, we present a number of programming frameworks that have been&nbsp;proposed as an alternative to MapReduce, developed under the premise of solving the shortcomings of this model in certain&nbsp;scenarios and platforms.</div>
<hr><ul><li>Marx, V.&nbsp;The Big Challenges of Big Data,&nbsp;NATURE&nbsp;498(7453):&nbsp;255-260, DOI:&nbsp;<a href="http://dx.doi.org/10.1038/498255a">10.1038/498255a</a>&nbsp;(2013)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper8&#39;)">Abstract:</a>&nbsp;</strong></p>
<div id="paper8" style="display:none;">Biologists are joining the big-data club. With the advent of high-throughput genomics, life scientists are starting to grapple with massive data sets, encountering challenges with handling, processing and moving information that were once the domain of astronomers and high-energy physicists.&nbsp;With every passing year, they turn more often to big data to probe everything from the regulation of genes and the evolution of genomes to why coastal algae bloom, what microbes dwell where in human body cavities and how the genetic make-up of different cancers influences how cancer patients fare. The European Bioinformatics Institute (EBI) in Hinxton, UK, part of the European Molecular Biology Laboratory and one of the world's largest biology-data repositories, currently stores 20 petabytes (1 petabyte is 1015&nbsp;bytes) of data and back-ups about genes, proteins and small molecules. Genomic data account for 2 petabytes of that, a number that more than doubles every year.</div>
<hr><ul><li>Wu, XD; Zhu, XQ; Wu, GQ; Ding, W.&nbsp;Data Mining with Big Data.&nbsp;IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING&nbsp;26(1):97-107,&nbsp;DOI:&nbsp;<a href="http://dx.doi.org/10.1109/TKDE.2013.109">10.1109/TKDE.2013.109</a>, (2014)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper7&#39;)">Abstract:</a>&nbsp;</strong></p>
<div id="paper7" style="display:none;">Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.</div>
<hr><ul><li>Chen, CLP; Zhang, CY.&nbsp;Data-intensive applications, challenges, techniques and technologies: A survey on Big Data.&nbsp;INFORMATION SCIENCES&nbsp;275:314-347&nbsp;DOI:&nbsp;<a href="http://dx.doi.org/10.1016/j.ins.2014.01.015">10.1016/j.ins.2014.01.015</a>, (2014)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper6&#39;)">Abstract:</a>&nbsp;</strong></p>
<div id="paper6" style="display:none;">It is already true that Big Data has drawn huge attention from researchers in information sciences, policy and decision makers in governments and enterprises. As the speed of information growth exceeds Moore's Law at the beginning of this new century, excessive data is making great troubles to human beings. However, there are so much potential and highly useful values hidden in the huge volume of data. A new scientific paradigm is born as data-intensive scientific discovery (DISD), also known as Big Data problems. A large number of fields and sectors, ranging from economic and business activities to public administration, from national security to scientific researches in many areas, involve with Big Data problems. On the one hand, Big Data is extremely valuable to produce productivity in businesses and evolutionary breakthroughs in scientific disciplines, which give us a lot of opportunities to make great progresses in many fields. There is no doubt that the future competitions in business productivity and technologies will surely converge into the Big Data explorations. On the other hand, Big Data also arises with many challenges, such as difficulties in data capture, data storage, data analysis and data visualization. This paper is aimed to demonstrate a close-up view about Big Data, including Big Data applications, Big Data opportunities and challenges, as well as the state-of-the-art techniques and technologies we currently adopt to deal with the Big Data problems. We also discuss several underlying methodologies to handle the data deluge, for example, granular computing, cloud computing, bio-inspired computing, and quantum computing.&nbsp;</div>
<hr><ul><li>Zhai Y, Ong Y, Tsang IW The emerging “big dimensionality”. IEEE Comp Int Mag 9(3):14–26, DOI:&nbsp;<a href="http://dx.doi.org/10.1109/MCI.2014.2326099">10.1109/MCI.2014.2326099</a>, (2014)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper5&#39;)">Abstract</a></strong>:</p>
<div id="paper5" style="display:none;">The world continues to generate quintillion bytes of data daily, leading to the pressing needs for new efforts in dealing with the grand challenges brought by Big Data. Today, there is a growing consensus among the computational intelligence communities that data volume presents an immediate challenge pertaining to the scalability issue. However, when addressing volume in Big Data analytics, researchers in the data analytics community have largely taken a one-sided study of volume, which is the "Big Instance Size" factor of the data. The flip side of volume which is the dimensionality factor of Big Data, on the other hand, has received much lesser attention. This article thus represents an attempt to fill in this gap and places special focus on this relatively under-explored topic of "Big Dimensionality", wherein the explosion of features (variables) brings about new challenges to computational intelligence. We begin with an analysis on the origins of Big Dimensionality. The evolution of feature dimensionality in the last two decades is then studied using popular data repositories considered in the data analytics and computational intelligence research communities. Subsequently, the state-of-the-art feature selection schemes reported in the field of computational intelligence are reviewed to reveal the inadequacies of existing approaches in keeping pace with the emerging phenomenon of Big Dimensionality. Last but not least, the "curse and blessing of Big Dimensionality" are delineated and deliberated.</div>
<hr><ul><li>Chen, M;&nbsp;Mao, SW; Liu, YH.&nbsp;Big Data: A Survey.&nbsp;MOBILE NETWORKS &amp; APPLICATIONS&nbsp;19(2):&nbsp;171-209,&nbsp;DOI:&nbsp;<a href="http://dx.doi.org/10.1007/s11036-013-0489-0">10.1007/s11036-013-0489-0</a> (2014)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper4&#39;)">Abstract:</a></strong></p>
<div id="paper4" style="display:none;">In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop. We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aim to provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.<br>
&nbsp;</div>
<hr><ul><li>O'Leary, DE.&nbsp;Artificial Intelligence and Big Data.&nbsp;IEEE INTELLIGENT SYSTEMS&nbsp;28(2):&nbsp;96-99, DOI:&nbsp;<a href="http://dx.doi.org/10.1109/MIS.2013.39">10.1109/MIS.2013.39</a>&nbsp;(2013)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper3&#39;)">Abstract:</a>&nbsp;</strong></p>
<div id="paper3" style="display:none;">AI Innovation in Industry is a new department for IEEE Intelligent Systems, and this paper examines some of the basic concerns and uses of AI for big data (AI has been used in several different ways to facilitate capturing and structuring big data, and it has been used to analyze big data for key insights)</div>
<hr><ul><li>Kraska, T&nbsp;Finding the Needle in the Big Data Systems Haystack.&nbsp;IEEE INTERNET COMPUTING&nbsp;17(1):84-86, DOI:&nbsp;<a href="http://dx.doi.org/10.1109/MIC.2013.10">10.1109/MIC.2013.10</a>&nbsp;(2013)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper2&#39;)">Abstract</a></strong>:</p>
<div id="paper2" style="display:none;">With the increasing importance of big data, many new systems have been developed to "solve" the big data challenge. At the same time, famous database researchers argue that there is nothing new about these systems and that they're actually a step backward. This article sheds some light on this discussion.</div>
<hr><ul><li>Sakr, S; Liu, AN; Fayoumi, AG,&nbsp;The Family of MapReduce and Large-Scale Data Processing Systems.&nbsp;ACM COMPUTING SURVEYS 46(1):11,&nbsp;DOI:&nbsp;<a href="http://dx.doi.org/10.1145/2522968.2522979">10.1145/2522968.2522979</a> (2013)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper1&#39;)">Abstract:</a></strong>&nbsp;</p>
<div id="paper1" style="display:none;">In the last two decades, the continuous increase of computational power has produced an overwhelming flow of data which has called for a paradigm shift in the computing architecture and large-scale data processing mechanisms. MapReduce is a simple and powerful programming model that enables easy development of scalable parallel applications to process vast amounts of data on large clusters of commodity machines. It isolates the application from the details of running a distributed program such as issues on data distribution, scheduling, and fault tolerance. However, the original implementation of the MapReduce framework had some limitations that have been tackled by many research efforts in several followup works after its introduction. This article provides a comprehensive survey for a family of approaches and mechanisms of large-scale data processing mechanisms that have been implemented based on the original idea of the MapReduce framework and are currently gaining a lot of momentum in both research and industrial communities. We also cover a set of introduced systems that have been implemented to provide declarative programming interfaces on top of the MapReduce framework. In addition, we review several large-scale data processing systems that resemble some of the ideas of the MapReduce framework for different purposes and application scenarios. Finally, we discuss some of the future research directions for implementing the next generation of MapReduce-like solutions.</div>
<hr><ul><li>M. D. Assunção; R. N. Calheiros, S. Bianchi, M. A.S. Netto, R. Buyyab. Big Data computing and clouds: Trends and future directions. JOURNAL OF PARALLEL DISTRIBUTED COMPUTING, DOI: <a href="http://dx.doi.org/10.1016/j.jpdc.2014.08.003">10.1016/j.jpdc.2014.08.003</a> in press (2015)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper10&#39;)">Abstract:</a></strong></p>
<div id="paper10" style="display:none;">This paper discusses approaches and environments for carrying out analytics on Clouds for Big Data applications. It revolves around four important areas of analytics and Big Data, namely (i) data management and supporting architectures; (ii) model development and scoring; (iii) visualisation and user interaction; and (iv) business models. Through a detailed survey, we identify possible gaps in technology and provide recommendations for the research community on future directions on Cloud-supported Big Data<br>
computing and analytics solutions</div>
<hr><ul><li>K. Kambatla, G. Kollias, V. Kumar, A. Grama. Trends in big data analytics. JOURNAL OF PARALLEL DISTRIBUTED COMPUTING, 74: 2561-2573, DOI: <a href="http://dx.doi.org/10.1016/j.jpdc.2014.01.003">10.1016/j.jpdc.2014.01.003</a> (2014)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper11&#39;)">Abstract:</a></strong></p>
<div id="paper11" style="display:none;">One of the major applications of future generation parallel and distributed systems is in big-data analytics. Data repositories for such applications currently exceed exabytes and are rapidly increasing in size. Beyond their sheer magnitude, these datasets and associated applications’ considerations pose significant challenges for method and software development. Datasets are often distributed and their size and privacy considerations warrant distributed techniques. Data often resides on platforms with widely varying<br>
computational and network capabilities. Considerations of fault-tolerance, security, and access control are critical in many applications (Dean and Ghemawat, 2004; Apache hadoop). Analysis tasks often have hard deadlines, and data quality is a major concern in yet other applications. For most emerging applications, data-driven models and methods, capable of operating at scale, are as-yet unknown. Even when known methods can be scaled, validation of results is a major issue. Characteristics of hardware platforms and the<br>
software stack fundamentally impact data analytics. In this article, we provide an overview of the state-of-the-art and focus on emerging trends to highlight the hardware, software, and application landscape of big-data analytics.</div>
<hr><ul><li>I. A. T. Hashem, I. Yaqoob, N. B. Anuar, S. Mokhtar, A. Gani, S.U. Khan. The rise of “big data” on cloud computing: Review and open research issues. INFORMATION SYSTEMS 47: 98-115, DOI: <a href="http://dx.doi.org/10.1016/j.is.2014.07.006">10.1016/j.is.2014.07.006</a> (2015)</li>
</ul><p class="rteindent1"><strong><a href="javascript:ReverseDisplay(&#39;paper12&#39;)">Abstract:</a></strong></p>
<div id="paper12" style="display:none;">Cloud computing is a powerful technology to perform massive-scale and complex computing. It eliminates the need to maintain expensive computing hardware, dedicated space, and software. Massive growth in the scale of data or big data generated through cloud computing has been observed. Addressing big data is a challenging and time-demanding task that requires a large computational infrastructure to ensure successful data processing and analysis. The rise of big data in cloud computing is reviewed in this study. The definition, characteristics, and classification of big data along with some discussions on cloud computing are introduced. The relationship between big data and cloud computing, big data storage systems, and Hadoop technology are also discussed. Furthermore, research challenges are investigated, with focus on scalability, availability, data integrity, data transformation, data quality, data heterogeneity, privacy, legal and regulatory issues, and governance. Lastly, open research issues that require substantial research efforts are summarized.</div>
<hr><h2><a id="slides" name="slides"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/Keynote-icon.png" style="width: 125px; height: 125px; float: left;">Keynote Slides</a></h2>
<p><strong><span style="font-size:16px;"><a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, "Data Mining Methods for Big Data Preprocessing"</span></strong>.&nbsp;Seminar at:&nbsp; <em>INIT/AERFAI Summer School on Machine Learning</em>, Benicàssim (Spain), June 22-26, 2015 &nbsp;<a href="http://sci2s.ugr.es/sites/default/files/files/TematicWebSites/BigData/Summer-School-Big%20Data%20preprocessing%20-%20Benicassim.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/iconPdf.png" style="width: 23px; height: 24px;"></a></p>
<p><strong><span style="font-size:16px;"><a href="http://sci2s.ugr.es/members#FHerrera">F. Herrera</a>, "A tour on big data classification. Selected Computational Intelligence approaches"</span></strong>. Plenary talk at:&nbsp;<em>16th IFSA World Congress &amp; 9th EUSFLAT Conference</em>, Gijón (Spain), June 30th - July 3rd, 2015 &nbsp;<a href="http://sci2s.ugr.es/sites/default/files/Big-data-IFSA-2015.pdf"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/iconPdf.png" style="width: 23px; height: 24px;"></a></p>
<p>&nbsp;</p>
<h2 class="rtejustify"><a id="Links" name="Links"><img alt="" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/links of interest 02.jpg" style="width: 122px; height: 100px; float: left;">Links of interest</a></h2>
<p><strong><strong><strong>&nbsp; </strong></strong></strong>Several related Web pages are linked in order to complement the information shown in this thematic Website.</p>
<p>&nbsp; Readers may<strong><strong><strong> </strong></strong></strong>find official Websites from the MapReduce technologies stressed here, i.e. Hadoop and Spark, together with several alternatives for graph programming, data streams, and MapReduce implementations over GPUs. Additionally, other interesting links includes open courses, blogs with information on Big Data / Data Science, and many other related Webs on the topic.</p>
<ul><li>Apache Hadoop's&nbsp;main webpage:&nbsp;<a href="https://hadoop.apache.org/">https://hadoop.apache.org</a></li>
<li>Apache Spark's main webpage: <a href="https://spark.apache.org/">https://spark.apache.org/</a></li>
<li>Apache Spark's API: <a href="https://spark.apache.org/docs/latest/api/scala/index.html">https://spark.apache.org/docs/latest/api/scala/index.html</a></li>
<li>Mahout Machine Learning library: <a href="http://mahout.apache.org/">http://mahout.apache.org/</a></li>
<li>Spark MLib:&nbsp;<a href="https://spark.apache.org/mllib/">https://spark.apache.org/mllib/</a></li>
<li>The Scala programming language:&nbsp;<a href="http://www.scala-lang.org/">http://www.scala-lang.org/</a></li>
<li>Apache Spark's packages: <a href="http://spark-packages.org/">http://spark-packages.org/</a></li>
<li>Rhipe (R+Hadoop):&nbsp;<a href="https://www.datadr.org/">https://www.datadr.org/</a></li>
<li>Vowpal Wabbit:&nbsp;<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">https://github.com/JohnLangford/vowpal_wabbit/wiki</a></li>
<li>Dryad (Directed Acyclic Graph model): <a href="http://research.microsoft.com/en-us/projects/dryad/">http://research.microsoft.com/en-us/projects/dryad/</a></li>
<li>Giraph (Bulk Synchronous Parallel model): <a href="http://giraph.apache.org/">http://giraph.apache.org/</a></li>
<li>Storm (Distributed real-time computation system): <a href="http://hortonworks.com/hadoop/storm/">http://hortonworks.com/hadoop/storm/</a></li>
<li>S4 (Distributed Stream Computing Platform): <a href="http://incubator.apache.org/s4/">http://incubator.apache.org/s4/</a></li>
<li>Phoenix (MapReduce for shared-memory systems - GPU):&nbsp;<a href="https://github.com/kozyraki/phoenix">https://github.com/kozyraki/phoenix</a></li>
<!--<li>Learning Spark: Lightning-Fast Big Data Analysis (book): http://www.amazon.com/Learning-Spark-Lightning-Fast-Data-Analysis/dp/1449358624/ref=sr_1_1?ie=UTF8&amp;qid=1425641857&amp;sr=8-1&amp;keywords=learning+spark</li>--><li>Databricks' web page: <a href="http://databricks.com/">http://databricks.com/</a></li>
<li>Gartner Big Data:&nbsp;<a href="http://www.gartner.com/it-glossary/big-data">http://www.gartner.com/it-glossary/big-data</a></li>
<li>Probabilistic Data Structures for Web Analytics and Data&nbsp;Mining: <a href="https://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/">https://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/</a></li>
<li>Big Data/Analytics Zone (blog): <a href="http://www.dzone.com/mz/big-data">http://www.dzone.com/mz/big-data</a></li>
<li>Coursera (open courses for Big Data / Data Science):&nbsp;<a href="https://www.coursera.org/">https://www.coursera.org/</a></li>
<li>Edx (Open courses for Apache Spark): <a href="https://www.edx.org/course?search_query=apache+spark">https://www.edx.org/course?search_query=apache+spark</a></li>
<li>Large Open-Big Data:&nbsp; <a href="http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public">http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public</a></li>
<li>Stack Overflow questions about Spark: <a href="http://stackoverflow.com/questions/tagged/apache-spark">http://stackoverflow.com/questions/tagged/apache-spark</a></li>
</ul><div><strong><strong><strong>&nbsp; </strong></strong></strong>
<hr><strong><strong><strong> </strong></strong></strong>
<h6 class="rtecenter"><strong><strong><strong>Page Maintained by A. Fernández, <a href="http://sci2s.ugr.es/members#SdelRio">S. Río</a>, <a href="http://sci2s.ugr.es/members#SRamirez">S. Ramírez-Gallego</a></strong></strong></strong></h6>
<p><strong><strong><strong> </strong></strong></strong></p></div>
</div></div></div></div>  </div>

      <footer>
          </footer>
  
    </div>
  
</div> <!-- /.block -->
</div>
 <!-- /.region -->
      </section> <!-- /#main -->
    </div>
  
          <aside id="sidebar-first" role="complementary">
        <div class="region region-sidebar-first">
  <div id="block-search-form" class="block block-search">

        <h2>Search on SCI2S</h2>
    
  <div class="content">
    <form action="http://sci2s.ugr.es/BigData" method="post" id="search-block-form" accept-charset="UTF-8"><div><div class="container-inline">
    <div class="form-item form-type-textfield form-item-search-block-form">
  <label class="element-invisible" for="edit-search-block-form--2">Search </label>
 <input title="Enter the terms you wish to search for." type="text" id="edit-search-block-form--2" name="search_block_form" value="" size="15" maxlength="128" class="form-text">
</div>
<div class="form-actions form-wrapper" id="edit-actions"><input type="submit" id="edit-submit" name="op" value="Search" class="form-submit"></div><input type="hidden" name="form_build_id" value="form-o9b4FgCEzTGzYmrW00G9L89ZrmoRfhGon2Gp2o4ZqdY">
<input type="hidden" name="form_id" value="search_block_form">
</div>
</div></form>  </div>
  
</div> <!-- /.block -->
<div id="block-block-1" class="block block-block">

        <h2>Thematic Web Sites</h2>
    
  <div class="content">
    <div class="tex2jax"><div style="float: left;">
<p><a href="http://sci2s.ugr.es/CWDM"><img alt="Computing with Words in Decision Making" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/CWDMlogo.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Computing with Words in Decision Making"></a> <a href="http://sci2s.ugr.es/sicidm"><img alt="Statistical Inference in Computational Intelligence and Data Mining" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo_stat.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Statistical Inference in Computational Intelligence and Data Mining"></a> <a href="http://sci2s.ugr.es/hindex"><img alt="h-index and Variants" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/hindex_logo1.gif" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="h-index and Variants"></a> <a href="http://sci2s.ugr.es/EAMHCO"><img alt="Evolutionary Algorithms and other Metaheuristics for Continuous Optimization Problems" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/eamhco_logo_grande.gif" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Evolutionary Algorithms and other Metaheuristics for Continuous Optimization Problems"></a> <a href="http://sci2s.ugr.es/fuzzyInterpretability"><img alt="Interpretability of Linguistic Fuzzy Rule-Based Systems: An Overview of Interpretability Measures" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/interpretability-FRBSs.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Interpretability of Linguistic Fuzzy Rule-Based Systems: An Overview of Interpretability Measures"></a> <a href="http://sci2s.ugr.es/pr"><img alt="Prototype Reduction in Nearest Neighbor Classification: Prototype Selection and Prototype Generation" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/prlogo.gif" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Prototype Reduction in Nearest Neighbor Classification: Prototype Selection and Prototype Generation"></a>&nbsp; <a href="http://sci2s.ugr.es/MVDM"><img alt="Missing Values in Data Mining" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/mvdm_logo_grande.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Missing Values in Data Mining"></a> <a href="http://sci2s.ugr.es/gfs"><img alt="Genetic Fuzzy Systems and Multi-Objective Evolutionary Fuzzy Systems: Taxonomy, Current Research Trends and Prospects" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/gfs1.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Genetic Fuzzy Systems and Multi-Objective Evolutionary Fuzzy Systems: Taxonomy, Current Research Trends and Prospects"></a> <a href="http://sci2s.ugr.es/imbalanced"><img alt="Classification with Imbalanced Datasets" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logo.gif" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Classification with Imbalanced Datasets"></a> <a href="http://sci2s.ugr.es/noisydata"><img alt="Noisy Data in Data Mining" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/noisy_data_icon.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Noisy Data in Data Mining"></a> <a href="http://sci2s.ugr.es/ssl"><img alt="Semi-supervised Classification: An Insight into Self-Labeling Approaches" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/ssl2.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Semi-supervised Classification: An Insight into Self-Labeling Approaches"></a> <a href="http://sci2s.ugr.es/fss"><img alt="Fuzzy Systems Software: Taxonomy, Current Research Trends and Prospects" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/fss1.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Fuzzy Systems Software: Taxonomy, Current Research Trends and Prospects"></a> <a href="http://sci2s.ugr.es/BigData"><img alt="Big Data" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/BigData_04.png" style="width: 67px; height: 50px; border-width: 1px; border-style: solid;" title="Big Data: Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes"></a> <a href="http://sci2s.ugr.es/books/data-preprocessing"><img alt="Data Preprocessing in Data Mining" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/datapreprocessing_sci2s_icon.png" style="height: 50px; border-width: 1px; border-style: solid; width: 67px;" title="Data Preprocessing in Data Mining"></a></p>
</div>
</div>  </div>
  
</div> <!-- /.block -->
<div id="block-block-3" class="block block-block">

        <h2>Ranking I-UGR</h2>
    
  <div class="content">
    <div class="tex2jax"><div style="float: left; clear: both;">
<p><a href="http://rankinguniversidades.es/"><img alt="Ranking I-UGR" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/rankingUGR.png" style="border-width: 1px; border-style: solid;" title="Ranking I-UGR"></a></p>
</div>
</div>  </div>
  
</div> <!-- /.block -->
<div id="block-block-2" class="block block-block">

        <h2>Software</h2>
    
  <div class="content">
    <div class="tex2jax"><div style="float: left;">
<p><a href="http://keel.es/"><img alt="KEEL" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/logoKeel.png" style="border-width: 1px; border-style: solid;" title="KEEL"></a> <a href="http://sci2s.ugr.es/scimat"><img alt="SciMAT" src="./Big Data_ Algorithms for Data Preprocessing, Computational Intelligence, and Imbalanced Classes _ Soft Computing and Intelligent Information Systems_files/scimatLogo.png" style="border-width: 1px; border-style: solid;" title="SciMAT"></a></p>
</div>
</div>  </div>
  
</div> <!-- /.block -->
</div>
 <!-- /.region -->
      </aside>  <!-- /#sidebar-first -->
      
    </div>

      
  <div class="clear"></div>
   
    </div> 
  

   
  <div id="footer">
     
      <div id="footer-area" class="clearfix">
                <div class="column"><div class="region region-footer-first">
  <div id="block-user-login" class="block block-user">

        <h2>User login</h2>
    
  <div class="content">
    <form action="http://sci2s.ugr.es/BigData?destination=node/284" method="post" id="user-login-form" accept-charset="UTF-8"><div><div class="form-item form-type-textfield form-item-name">
  <label for="edit-name">Username <span class="form-required" title="This field is required.">*</span></label>
 <input type="text" id="edit-name" name="name" value="" size="15" maxlength="60" class="form-text required">
</div>
<div class="form-item form-type-password form-item-pass">
  <label for="edit-pass">Password <span class="form-required" title="This field is required.">*</span></label>
 <input type="password" id="edit-pass" name="pass" size="15" maxlength="128" class="form-text required">
</div>
<div class="item-list"><ul><li class="first last"><a href="http://sci2s.ugr.es/user/password" title="Request new password via e-mail.">Request new password</a></li>
</ul></div><input type="hidden" name="form_build_id" value="form-56Us1qgG-p-r4AJf3M2UdozgMeL4FFcikCd1yWQ8xQ0">
<input type="hidden" name="form_id" value="user_login_block">
<div class="form-actions form-wrapper" id="edit-actions--2"><input type="submit" id="edit-submit--2" name="op" value="Log in" class="form-submit"></div></div></form>  </div>
  
</div> <!-- /.block -->
</div>
 <!-- /.region -->
</div>
                        <div class="column"><div class="region region-footer-second">
  <div id="block-menu-menu-sci2s-web-site-related" class="block block-menu">

        <h2>SCI2S Web-site Related</h2>
    
  <div class="content">
    <ul class="menu"><li class="first leaf"><a href="http://sci2s.ugr.es/webmasters">About the Webmaster Team</a></li>
<li class="leaf"><a href="http://sci2s.ugr.es/logos">Logos, Images, etc.</a></li>
<li class="last leaf"><a href="http://sci2s.ugr.es/siteStatistics">Site Statistics</a></li>
</ul>  </div>
  
</div> <!-- /.block -->
</div>
 <!-- /.region -->
</div>
                      </div>
          
    <div id="copyright">
    <!--Remove  -->
          	<p class="copyright">Copyright © 2003 - 2016, SCI<sup>2</sup>S Research Group</p>
          <!--Remove Theme Credit by Setting -->
       
     		<p class="credits"> Theme Originally Created by  <a href="http://www.devsaran.com/">Devsaran</a></p>
         <div class="clear"></div>
    </div>
  </div>
</div>
<a href="http://sci2s.ugr.es/BigData#" class="back-to-top" style="display: inline;">Volver Arriba</a>
  

<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_Size2, sans-serif;"></div></div></body></html>